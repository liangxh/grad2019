\chapter{面向三轮对话的情感识别}
\label{cha:exp_context_emo}

\section{本章引论}

情感识别是意图识别中的核心课题之一，它尝试理解人们对特定对象如人物、机构、产品、服务等的情感倾向。虽然后自然语言处理领域已经有很长一段研究历史，但截至2000年为止针对人物情感和想法的研究甚少\cite{liu2012sentiment}，而在2000年后情感识别开始受到关注，其中有以下几个的原因。首先是在各个领域出现了相关需求，商业上的需求间接导致资金支持的增加，基于情感识别的应用也因此得以发展，这些都为情感识别带来了研究动力。其次是数据的支持，在互联网出现前数据的收集普遍要透过人工完成，而在2000年后互联网逐渐普及，社交媒体的使用使得可供分析的数据远超于以前，数据的收集也更加便捷，这为研究提供了充足的数据基础。

面向文本的情感识别存在一些先天的难点。首先是一词多义，譬如在中文里“算账”有计算法资金收支或结余的意思，有引伸义为吃亏之后与人争执较量，又譬如在英文里“suck”有吸取或吸入物的意思，而在俚语中则有使人厌恶的意思，以上两个例子都是一个词可以在不同场景下表现中性和负性两种情感，这在情感识别中会导致混淆。其次是明显情感极性的词和发言者的情感无关，譬如“我想要挑一台好的电脑”，这里“好”有明显正向的词，但和发言者的情感无关，原句的情感应偏向于中性。第三是不带情感但包含情感极性的词组，譬如“打印机又卡纸了”的字面意思是偏中性的，但根据具体场景的经验，我们能猜想到发言者可能处于不耐烦的状态，间接表达的是负向的情感。最后是前面提到的反讽的修辞使用，透过表面上表现为正性的语句表达负性的情感。特别地，这些情况即使由人工识别也有可能会被混淆。

为了缓解在句子内部存在二义的问题，一些研究考虑引入上下文来提供辅助信息。譬如Zahiri和Choi\cite{Zahiri2017Emotion}在研究电影剧剧本情感识别时，就引入了前后的发言作为上下文信息来建模。而国际比赛SemEval-2019的任务三\cite{SemEval2019Task3}则是旨在促进引入上下文背景的文本情感识别研究，比赛要求参赛者开发一个情感识别系统，对三轮对话中最后一轮发言表达的情感进行分类，给定的四个情感类别包括：开心、悲伤、愤怒、其他。本章节中我们将基于SemEval-2019的任务三进行实验，采用比赛组织者提供的训练数据和测试数据，并透过和其他参赛系统进行比较来评估我们提出的框架的性能。

本章的内容安排如下。在章节\ref{sec:exp_context_emo_format}中，我们会基于章节\ref{sec:global_problem_analysis}首先给出当前问题的形式化表示。在章节\ref{sec:exp_context_emo_data}中我们再对具体实验数据进行观察，分析给定数据集中各个情感类别的分布情况以及其文本特性。在章节\ref{sec:exp_context_emo_framework}中，我们会基于章节\ref{sec:global_framework}的框架给出我们对当前问题的系统框架。最后在章节\ref{sec:exp_context_emo_exp}给出实验的细节，以及对实验结果进行分析。

\section{形式化表示}
\label{sec:exp_context_emo_format}

在本章中，我们要研究三轮对话的情感识别。给定一个情感类别集合$C$，对于一个三轮对话的集合$S$，其中任意一个样本$s$可以表示为一个三元组$<t^1, t^2, t^3>$对应三段文本，其中最后一轮发言$t^3$是被识别情感的主体，上下文$b=<t^1, t^2>$是$t^3$的背景信息。假设$t^3$在背景$b$下属于唯一一种情感倾向$c \in C$。又给定一个词集合$W$，对任意一轮的文本$t^j, j=1,2,3$，经过文本预处理后可以表示为一个长度为$L^j$的词序列 $w^j = <w^j_1, w^j_2, ..., w^j_{L^j}>, w^j_i \in W, i \in [1, L^j]$。那么我们的目标是找出一个映射关系$F_C$，使得$c=F_C(w^3, <w^1, w^2>)$。

\section{数据观察}
\label{sec:exp_context_emo_data}

我们的实验完全采用SemEval-2019的任务三比赛组织者提供的数据集，其中每个样本对应一个三轮对话以及第三轮发言的情感标签，第一轮为用户甲的发言（以下简称为A1），第二轮为用户乙对第一轮的回复（以下简称为B），第三轮为用户甲对第二轮中用户乙的回复（以下简称为A2）。情感标签对应四个情感类别中的其中一种：开心、悲伤、愤怒、其他。表\ref{tab:semeval_2019_task3_data}显示数据集各类别样本数量分布，表\ref{tab:semeval_2019_task3_sample}。

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{0.8\linewidth}
  \caption{情感识别各类别样本数量分布}
  \label{tab:semeval_2019_task3_data}
    \begin{tabularx}{\linewidth}{X|XXXX}
    \toprule[1.5pt]
    数据集 & 其他 & 开心 & 悲伤 & 愤怒 \\  
    \hline
    训练集 & 14948 & 4243 & 5463 & 5506 \\
    验证集 & 2338 & 142 & 125 & 150 \\
    测试集 & 4677 & 284 & 250 & 298 \\
    \bottomrule[1.5pt]
    \end{tabularx}
  \end{minipage}
\end{table}

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{\linewidth}
  \caption{情感识别各类别样例}
  \label{tab:semeval_2019_task3_sample}
    \begin{tabularx}{\linewidth}{l|XXX}
    \toprule[1.5pt]
    \small 情感类别 & 第一轮 & 第二轮 & 第三轮 \\
    \hline
    \small 开心 & live in uttra khand & ohh nice! love that place!∧.∧ & :):) \\
    \small 悲伤 & Not coz of you & why? Tell me & :( My girlfriend left me \\
    \small 愤怒 & He is over me & so YOU say & I just hate him \\  
    \small 其他 & degreee & what degree \& where? & sryyy i really got to goo\\
    \bottomrule[1.5pt]
    \end{tabularx}
  \end{minipage}
\end{table}

可见在训练集上四个类别的样本分布约为3:1:1:1 ，而在验证集和测试集上四个类别的样本分布约为22:1:1:1 。在测试集上“其他”一类的样本远高于其他三个类别，和训练集相比其样本比例也相对较高，而另外三个类别的样本数量则大致相同。

另外在官方的最终测试阶段，训练集和验证集均已公布情感标注并且可用于模型训练，因此我们在模型训练时结合了这个两个数据集，而在后续内容我们以训练集代表这个结合后的数据集。

\subsection{文本长度}

我们首先对数据集的文本经过简单分词后统计各个类别的样本中词数量的分布，以下简称为文本长度。表\ref{fig:context_emo_train_class_len}显示在训练集上各情感类别的样本在每轮发言的文本长度分布，可以看出在每一轮的发言中，不同类别样本的文本长度分布大致相同。虽然第一轮和第三轮的样本中最长的文本分别达到146个词和74个词，各轮样本的文本长度大部分在22个词以内，约为第\ref{cha:exp_irony_det}章中样本长度的一半。

\begin{figure}[h]
  \centering%

  \begin{minipage}{\linewidth}

  \subcaptionbox{第一轮\label{fig:context_emo_train_class_len_0}} %[3cm] 
    {\includegraphics[height=8cm]{img/semeval2019_task3_train_0_class_len.png}}%
  %\hspace{em}%
  \subcaptionbox{第二轮\label{fig:context_emo_train_class_len_1}}
      {\includegraphics[height=8cm]{img/semeval2019_task3_train_1_class_len.png}}

  \end{minipage}
  \vspace{0.5cm} 

  \subcaptionbox{第三轮\label{fig:context_emo_train_class_len_2}}
      {\includegraphics[height=8cm]{img/semeval2019_task3_train_2_class_len.png}}

  \caption{训练集上各情感类别的样本在每轮发言的文本长度分布}

  \label{fig:context_emo_train_class_len}
\end{figure}

\subsection{文本特征}
\label{ssec:exp_context_emo_data_text}

对于比赛中提供的数据集，比赛组织者并没有给出数据的具体来源，但经过人工观察后我们可以发现一些社交网络上常见的文本特征，其中出现频率较高的模式如下：

\begin{itemize}

\item 大量的缩略词使用，如“u”代替“you”，“y”代替“why”，“im”代替“I am”。和微博以及讨论区等场景相比，可以认为在聊天场景下，用户会倾向于更快速的响应，使用缩略语减少需要输入的字符从而加快了回覆消息的速度。

\item 出现在句子最前或最后的表情符，其中包括Unicode定义表情符和由标点符号组成的表情符两类。

\item 一些在社交媒体平台上常见的、有别于正规英语的用法，如拼写错误、全大写字母的单词等，可以参考章节\ref{sec:text_preprocess}描述的例子。

\end{itemize}

\subsection{各轮发言间的情感信息}
\label{ssec:exp_context_emo_multi_turn_analyse}

为了结合多轮发言的信息来预测最后一轮发言的情感，我们需要观察各轮发言是对最后一轮发言的情感有提示作用，如果有的话应该如何利用这些提示信息来进行识别，并将此机制体现在分类器模型的设计当中。以下我们将采用数据集中的具体例子解释我们对语料的观察和分析。

首先，对于三轮发言中两个用户的情感，我们发现用户甲和用户乙表达的情感可能截然不同，参考以下例子：

\makebox[4 cm]{（第一轮）用户甲:} yes yay fun\par
\makebox[4 cm]{（第二轮）用户乙:} are not you joining us? :( \par
\makebox[4 cm]{（第三轮）用户甲:} yes\par

用户甲在最后一轮发言的情感标签为“开心”，而第一轮发言在字面意思上同样偏向正面。而对于用户乙在第二轮的发言，根据上下文意思和最后文本末尾的“:(”，我们可以推断用户乙的情感为“伤心”。可见三轮对话中两个用户的表达的情感可能不同甚至矛盾，因此用户甲的发言和用户乙的发言对识别第三轮发言的情感应起着不同的作用，第二轮中用户乙的发言甚至没有提示的作用。

另外对于用户甲，我们发现他在第一轮和第三轮中表达的情感也有可能不同，参考以下例子：

\makebox[4 cm]{（第一轮）用户甲:} not fine\par
\makebox[4 cm]{（第二轮）用户乙:} why? :'o \par
\makebox[4 cm]{（第三轮）用户甲:} tomorrow lab exam\par

用户甲在最后一轮发言的情感标签为“悲伤”，而在字面意思上，最后一轮发言的情感偏中性，只是在陈述“明天有考试”的事情，“悲伤”的情感提示主要来自用户甲在第一轮中表示自己的情况“不太好”，第三轮发言在解释“不太好”的原因。基于此例子可以认为，同为用户甲发言的第一轮在某此情况下对识别第三轮发言的情感起着决定性作用。再观察下面的例子：

\makebox[4 cm]{（第一轮）用户甲:} ohh sorry\par
\makebox[4 cm]{（第二轮）用户乙:} do not worry, you are not the first \par
\makebox[4 cm]{（第三轮）用户甲:} glad to hear\par

用户甲在最后一轮发言的情感标签为“开心”，对于用户甲在第一轮发言表达的情感，结合用户乙在第二轮的发言，可以认为用户甲在第一轮发言中表示对用户乙的同情，这与“开心”为不同的情感，而在用户乙发言后，用户甲情感因为用户乙说的话而转换成“开心”。可见用户甲在第一轮和第三轮中表达的情感有可能不同，这种情感的转变可能由用户乙的发言造成，但无论具体原因是什么，用户甲在第一轮和第三轮中的发言对识别第三轮发言的情感应起着不同的作用。

再者，我们发现用户甲在第三轮发言中可能出现多于一种情感，参考以下例子：

\makebox[4 cm]{（第一轮）用户甲:} \includegraphics[height=1.5\fontcharht\font`\B]{img/emoji/laugh.png} yes yes \par
\makebox[4 cm]{（第二轮）用户乙:} :3 you seem like a happy person \par
\makebox[4 cm]{（第三轮）用户甲:} yes \includegraphics[height=1.5\fontcharht\font`\B]{img/emoji/lol.png} happy outside, \includegraphics[height=1.5\fontcharht\font`\B]{img/emoji/frown.png} sad inside \par

用户甲在最后一轮发言的情感标签为“悲伤”，而在文本上，第三轮发言的前半表现为正面情感，后半表现为负表情感，前后的情感出现了转变。对于当第三轮发言中出现两种情感时情感标签以何者为准，比赛组织者并没有给出细节的说明，但对语料的观察可以发现普遍以后面出现的情感为主。

最后总给我们对语料中的样本进行的人工观察，我们发现三轮发言对识别第三轮发言的情感应起着不同的作用。当第三轮发言有明显的情感表达，我们可以无视前两轮发言的信息得出识别结果。当第三轮发言表达的情感较隐晦或偏中性，需要参考同为用户甲发言的第一轮的信息。第二轮发言的信息对情感识别没有明显的辅助作用，有待实验中进一步确认。

\section{框架设计}
\label{sec:exp_context_emo_framework}

我们提出的识别系统包含了三组分类器，分别面向不同的子分类问题，并依次经过三次投票结合各组分类器的预测结果来得出最终的预测结果。第一组分类器由$N_1$个四类分类器组成，对应原问题的四个类别：“开心”、“悲伤”、“愤怒”和“其他”。第二组分类器由$N_2$个三类分类器组成，用于区分“开心”、“悲伤”和“愤怒”三类。第二组分类器由$N_3$个二类分类器组成，用于区分“其他”和“不是其他”两类（即把“开心”、“悲伤”、“愤怒”视为一个情感类别）。

对于一条待识别的微博，决策过程如下：

\begin{itemize}

\item 首先由第一组分类器内部进行多数投票得出$Label^{1}_{MV}$作为第一轮的预测结果$Label_{I}$。为方便阅读，以下将对一组样本的第一轮预测结果称为中间结果I。

\item 第二步，由第二组分类器投票进行多数投票得出预测结果$Label^{2}_{MV}$，若超过$thr_{2}$分类器投票投给$Label^{2}_{MV}$且第一轮的预测结果$Label_{I}$为“其他”以外的三种情感类别之一，则把预测结果修改为$Label^{2}_{MV}$，否则保持不变，以此得出第二轮的预测结果$Label_{II}$。为方便阅读，以下将对一组样本的第二轮预测结果称为中间结果II。

\item 最后步，由第三组分类器分别得出预测结果，若超过$thr_{3}$分类器投票投给“其他”且第二轮的预测结果$Label_{II}$不是“其他”，则把预测结果修改为“其他”，否则保持不变，以此得出第三轮的预测结果$Label_{III}$，同时作为整个系统对该三轮对话的最终情感识别结果。

\end{itemize}

整个决策过程可以分成两大部分。第一部分是初步完成对第三轮发言的四分类情感识别，作为后续决策的基础，对应上述三步决策中的第一步。第二部分是基于第一部分的初步识别结果进行修正，对应上述三步决策中的后两步。第二步只关注于对“开心”、“悲伤”和“愤怒”三类的识别进行调整，因此对第一轮中被识别为“其他”的样本不作改动。而第三步则是关注于对“其他”一类的召回，这受启发于样本的数据分布的不均匀。在原比赛中，组识者在最后的测试阶段虽然没有给出各个样本的真实标签，但指出了“其他”、“开心”、“悲伤”和“愤怒”四个类别在测试集上的样本比例约为88:4:4:4 ，而在训练集上的比例约为55:15:15:15 ，“其他”的样本占比在测试集上要远高于训练集。因为针对性提高“其他”一类的召回有助于提高系统在测试集上的性能。值得注意的是虽然在大部分情况下，我们无法得出应用场景的真实标签，但可以透过社会学和统计学等手段评估应用场景上各类样本的分布。而为了模型训练，我们可以人为控制训练数据上各类样本的比例。在了解到训练集和测试集上样本数据分布存在差异的情况下，提高系统对个别类别的识别倾向，其中存在其合理性。另外，虽然此框架中第二部分的设计和章节\ref{sec:exp_irony_det_framework}中的有所不同，但同样引入了可信度的概念，第二步和第三步都只在足够多个分类器给出相同结果时才对上一轮的结果进行修正。

\begin{figure}[H]
  \centering
  \includegraphics[width=0.9\textwidth]{img/context_emo_system.pdf}
  \caption{三轮对话的情感识别系统框架}
  \label{fig:context_emo_system}
\end{figure}

其中对于每个子分类问题，我们都采用了相同的模型框架，如图\ref{fig:context_emo_cls_framework}所示，每个子分类器的输入为三轮对话对应的词序列$\{w^1, w^2, w^3\}$。根据在章节\ref{ssec:exp_context_emo_multi_turn_analyse}中的分析，我们认为三轮的发言对识别第三轮发言的情感起着不同的作用，因此三轮发言对应的词序列分别进入各自的通道。每个通道的结构相同，第一步都是把词序列转换成对应的词嵌入向量序列，作为特征编码器的输入。此处特征编码器的设计与章节\ref{sec:exp_irony_det_framework}中的相同，目的是把单轮发言对应的词向量序列转换成固定长度的特征向量，以此得出该轮发言的特征向量。为了简化，三个通道的特征编码器采用相同的模型，但考虑到每轮发言的信息中对第三轮情感有关的特征可能不同，故三组模型有各自采用不同的权重。分别得出三轮发言的特征向量后我们需要结合这些特征来预第三轮的情感类别，此处我们直接把三个向量拼接成一个向量，作为概率预测器的轮入。此处概率预测器的设计与章节\ref{sec:exp_irony_det_framework}中的相似，但实现上采用了两层的全联接层，第一层接的激活函数为线性整流函数（Rectified Linear Unit, ReLU），而第二层的激活函数依然为$Softmax$，以得出各个情感类别的概率分布。

同样地，考虑到对于面向不同情感类别的子分类问题，不同模型的建模能力和识别性能可能不同，所以对于每个子分类问题，我们会分别比较各组模型和参数的性能，以求在子分类问题上达到尽可能好的效果。

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{img/context_emo_cls_framework.pdf}
  \caption{三轮对话的情感识别子分类器模型框架}
  \label{fig:context_emo_cls_framework}
\end{figure}

\section{实验与分析}
\label{sec:exp_context_emo_exp}

\subsection{数据预处理}

基于我们在章节\ref{ssec:exp_context_emo_data_text}中对样本文本的观察，我们依次采取了以下数据预处理手法

\begin{itemize}

\item 全字母大写的内容在前后添加“<allcap>”和“</allcap>”，示意这一段文本可能是用户故意表示强调的内容。

\item 重复大于等次三次的标点符号以“<repeated>”示意，如“!!!”替换成序列“!”和“<repeated>”，表示“!”被多次重复以表达语气加强，同时假设重复次数不影响反讽的类型。

\item 将字母被故意重复的单词以“<elongated>”示意，如“Noooooooo”替换成序列“No”和“<elongated>”，表示“No”中某一个或多个字母被多次重复，但假设被重复的字符和重复的次数与反讽类型无关。

\item 将数字串替换成“<num>”，将电话号码替换成“<phone>”，将日期和时间分别替换成“<date>”和“<time>”，将数字百分比替换成“<percentage>”，超链接替换成“<url>”

\item 将由多个标点符号组成的表情符替换成对应的情感标签，如将“:)”替换成“<happy>”，将“:((”替换成“<sad>”。

\item 在完成以上处理后，对英文的大小写统一转换成小写。

\end{itemize}

\subsection{实验设置}

以下实验主要分成两大部分。第一部分是分析不同模型在不同子分类问题下的性能，根据章节\ref{sec:exp_context_emo_framework}，我们最终的反讽识别框架涉及以下多个子分类问题：区分“开心”、“悲伤”、“愤怒”和“其他”的四分类问题，区分“开心”、“悲伤”和“愤怒”的三分类问题、区分“其他”和“不是其他”的二分类问题。对于各个子分类问题，我们基于章节~\ref{sec:exp_context_emo_framework}中的子分类模型框架进行实验，透过采用不同配置了解不同模型对三轮对话的情感识别能力。

第二部分是分析我们设计的识别系统的性能。我们会观察每一轮决策的调整如何改变局部的预测结果，而这些局部变化如何影响系统的整体性能。

\subsection{评价指标}
\label{ssec:exp_context_emo_eval_metric}

按照国际比赛SemEval-2019任务三的设置，系统性能以针对“开心”、“悲伤”和“愤怒”三个情感类别的F1值（以下记为 $F_\mu$）作为识别系统性能的主要评价指标。其定义如下：

\begin{align}
  F_\mu &= \frac{2 \times P_\mu \times R_\mu}{P_\mu + R_\mu}
\end{align}

其中 $P_\mu$ 和 $R_\mu$ 分别是针对“开心”、“悲伤”和“愤怒”三个情感类别的正确率和召回率，其定义如下：

\begin{align}
  P_\mu &= \frac{\sum\limits_{c \in C} TP_c}{\sum\limits_{c \in C}(TP_c + FP_c)} \\
  R_\mu &= \frac{\sum\limits_{c \in C} TP_c}{\sum\limits_{c \in C}(TP_c + FN_c)}
\end{align}

其中 $C$对应情感类别集合\{开心，悲伤，愤怒\}，$TP_c$表示被系统预测为类别$c$，且真实标签为类别$c$的样本数量；$FP_c$表示被系统预测为类别$c$，但真实标签不是类别$c$的样本数量；$FN_c$被系统预测为不是类别$c$，但真实标签为类别$c$的样本数量。 

%另外，原比赛虽然以 $F_\mu$ 为排名的主要指标，但比赛组织者同样关注各个情感类别的F1值，因此在以下实验结果分析中我们也会这些指示进行观察，从而以不同角度了解系统识别性能。各个情感类别的F1值定义如下：

%\begin{align}
%  F_c &= \frac{2 \times P_c \times R_c}{P_c + R_c}
%\end{align}

%其中 $P_c$ 为类别$c$的正确率，$R_c$ 为类别$c$的召回率，其定义如下：

%\begin{align}
%  P_c &= \frac{TP_c}{TP_c + FP_c} \\
%  R_c &= \frac{TP_c}{TP_c + FN_c}
%\end{align} 

%其中$TP_c$，$FP_c$，$FN_c$的定义和前面的相同。

\subsection{模型训练}
\label{ssec:exp_context_emo_model_training}

对于不同的模型，我们都采用了以下策略来进行训练：

\begin{itemize}

\item 对于涉及类别“其他”的子分类问题，我们在训练前会基于“其他”的每一个样本随机生成一个新的临时样本（在训练不同子分类器时会各自生成临时样本）。生成方法是在三轮发言中随机选择一轮，再在该轮发言的文本中随机选择一个词删掉，以此摸拟用户使用未被识别的单词或错拼词，得出一个“其他”的新样本。这使得模型对识别“其他”的鲁棒性更好，但同时倾向于将更多不是“其他”的样本识别为“其他”。对于为什么只基于类别“其他”的样本生成新的临时样本，原因在于在语料中，忽略一个单词基本上不影响文本表达“其他”的情感，但对于类别“开心”、“悲伤”和“愤怒”，大部分样本仅由一个或少数几个单词决定其情感属性，若其中的一个单词被忽略会直接导致其情感属性变成中性（即“其他”），为避免产生有误导性的临时样本，我们只基于类别“其他”的样本生成新的样本。

\item 对于每个子分类器，先从每一类的训练样本中随机选出10\%的样本作为验证集，以此保留各个类的样本量分布。在每一轮模型训练中，学习算法基于另外90\%的训练样本对网络参数进行调整，然后计算模型在验证集上的性能，经过有限轮迭代后，取在验证集上某个特定性能指标达到最优的网络参数作为该子分类器最终的参数，以此缓解在训练数据上过拟合的问题。对于第一组分类器（“开心”、“悲伤”、“愤怒”和“其他”四分类）和第二组分类器（“开心”、“悲伤”和“愤怒”三分类），我们采用章节~\ref{ssec:exp_context_emo_eval_metric}中定义的针对“开心”、“悲伤”和“愤怒”的正确率$P_\mu$作为选择参数的性能指标，原因在于人工神经网络对各个类别的识别倾向与训练过程中遇到各类别的样本分布相关（若每个样本在反向传播时的权重相同），而测试集中“开心”、“悲伤”和“愤怒”的样本占比要低于验证集（验证集保留了训练集上各个类别的样本量分布），这导致模型在测试集上较容易把“其他”误判为这三种情感之一，使得正确率$P_\mu$数值明显下降，间接拉低了F1值$F_\mu$，故选择正确率$P_\mu$来确保模型的正确率$P_\mu$尽可能高。而对于第三组分类器（“其他”和“不是其他”二分类），我们采用针对类别“其他”的正确率作为选择参数的性能指标，原因在于对第三组分类器，我们的核心目的是尽可能有信心地召回“其他”的样本，因此要确保单个模型的正确率，而第三组分类器对“其他”样本的召回能力则由分类器的数量弥补。

\item 对于词嵌入层，我们利用了章节\ref{ssec:embedding}中提到的Baziotis等人\cite{baziotis2018ntua}提供的词嵌入模型，直接用于初始化词嵌入层的参数。在训练过程中，我们不对词嵌入层的参数进行调整。另外对于词嵌入模型中未被覆盖的单词，若它在至少2个训练样本中出现，则为其随机生成词向量。原因参考章节\ref{ssec:exp_irony_det_model_training}。

\item 在训练阶段中，我们在词嵌入层后添加高斯噪音。由于词嵌入算法在原理上使得意思相似的单词投影到词嵌入空间中距离相近的点上，高斯噪音的添加相当于把原本的单词替换成近义词，使得模型能更好地识别近义词构成的语言模式，另一方面缓解过拟合的问题。在验证和测试阶段，高斯躁音的标准方差被调整为零，即不起作用。

\item 在训练阶段中，我们在三个通道的特征编码器后分别添加了Dropout层，以概率$p_{Dropout}$将特征编码器得出特征向量上的各位数值置为零，并对没有被置零的各位数值乘以常量 $\frac{1}{1-p_{dropout}}$。在验证和测试阶段，Dropout层不起作用。

\item 在模型训练的损失函数，我们以权重$l_2$加入了概率预测器中两个全联接层的权重（不包括偏移量）的L2正则项。

\end{itemize}

\subsection{结果与分析}

\subsubsection{面向情感四分类的模型性能分析}
\label{sssec:exp_context_emo_0_base}

对于面向三轮对话的情感四分类问题，表~\ref{tab:exp_context_emo_0_result}和图~\ref{fig:exp_context_emo_0_result_bar}显示不同卷积神经网络和迭归神经网络在测试集上能达到的性能。注意表中的正确率、召回率、F1值为
针对“开心”、“悲伤”和“愤怒”的指标，对应比赛SemEval2019任务三关注的主要指标，即章节~\ref{ssec:exp_context_emo_eval_metric}中定义的$P_\mu$、$R_\mu$和$F_\mu$。

对于F1值，CNN达到最好的0.7437 ，其次是的BiGRU配合注意力机制和CNN配合注意力机制，两者和第一的CNN差距较大（约0.0384）。对于准确率，同样是CNN的数值最高（0.9245），第二和第三分别是BiGRU配合注意力机制和GRU配合注意力机制，同样地和CNN差距较大（约0.0102）。对于正确率，则是GRU配合注意力机制的性能最优（0.7330），其次的GRU和CNN的前者差距较小（仅0.0034）。对于召回率，第一位依然是CNN（0.7584），其次是CNN配合注意力机制，和前者差距约0.0156，第三的BiGRU配合注意力机制则和前两者差距较大（数值低于0.7）。

总的来说，CNN同时在F1值、准确率和召回率三项指标上达到了最好的性能，而正确率同样逼近最好的GRU配合注意力机制，可见CNN在此子分类问题上有显着较好的建模能力。另外值得注意的是LSTM配合注意力机制在各项指标中数据最低，其中正确率、召回率和F1值都远低于其他模型，经过检查后发现该模型在多次训练中都会对“忽略”训练样本数较少的
“开心”、“悲伤”和“愤怒”中的某个类，如表~\ref{tab:exp_context_emo_0_result}中LSTM一行对应的分类器则是在训练集和测试集上都没有对任何一个样本识别为“愤怒”，导致“愤怒”的召回率为0。在排除算法实现有问题的可能性后，我们认为这是由于模型无法同时对四个类别建模所致，即数学模型与语料背后的模式不符。

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{\linewidth}
  \caption{面向情感四分类器的模型性能}　
  \label{tab:exp_context_emo_0_result}
    \begin{tabularx}{\linewidth}{X|llll}
    \toprule[1.5pt]
    & 准确率 & 正确率 & 召回率 & F1值 \\
    \hline
    CNN & \bf 0.9245 (1) & 0.7295 (3) & \bf 0.7584 (1) & \bf 0.7437 (1) \\ % f_cnn_ek_1554546621
    CNN+注意力机制 & 0.9071 (5) & 0.6574 (8) & 0.7428 (2) & 0.6975 (3) \\ % f_cnn_ek_1554545828
    \hline
    GRU & 0.9052 (8) & 0.7296 (2) & 0.5481 (9) & 0.6259 (9) \\ % f_gru_ek_1554462561
    GRU+注意力机制 & 0.9105 (3) & \bf 0.7330 (1) & 0.5974 (8) & 0.6583 (7) \\ % f_gru_ek_1554542220
    \hline
    BiGRU & 0.9067 (7) & 0.6598 (7) & 0.6923 (4) & 0.6757 (5) \\ % f_bgru_ek_1554465482
    BiGRU+注意力机制 & 0.9143 (2) & 0.7162 (4) & 0.6947 (3) & 0.7053 (2) \\ % f_bgru_ek_1554524728
    \hline
    LSTM & 0.9071 (5) & 0.6709 (6) & 0.6911 (5) & 0.6809 (4) \\ % f_lstm_ek_1554465719
    LSTM+注意力机制 & 0.8553 (10) & 0.2994 (10) & 0.2788 (10) & 0.2887 (10) \\ % f_lstm_ek_1554560984
    \hline
    BiLSTM & 0.8969 (9) & 0.6331 (9) & 0.6659 (6) & 0.6491 (8) \\ % f_blstm_ek_1554524691
    BiLSTM+注意力机制 & 0.9092 (4) & 0.7067 (5) & 0.6226 (7) & 0.6620 (6) \\ % f_blstm_ek_1554542227
    \bottomrule[1.5pt]
    \end{tabularx}
  \end{minipage}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{img/exp_context_emo_0_result_bar.png}
  \caption{面向情感四分类器的模型性能}
  \label{fig:exp_context_emo_0_result_bar}
\end{figure}

\subsubsection{面向“开心”、“悲伤”和“愤怒”三分类的模型性能分析}
\label{sssec:exp_context_emo_tri_base}

对于面向三轮对话的“开心”、“悲伤”和“愤怒”三分类问题，表~\ref{tab:exp_context_emo_tri_result}和图~\ref{fig:exp_context_emo_tri_result_bar}显示不同卷积神经网络和迭归神经网络在测试集上能达到的性能。注意表中的正确率、召回率、F1值同样对应章节~\ref{ssec:exp_context_emo_eval_metric}中定义的$P_\mu$、$R_\mu$和$F_\mu$。

对于表中的四个指标，均由CNN达到最好的效果。对于F1值，排第二和第三的分别是CNN配合注意力机制以及GRU配合注意力机制，两者和CNN的F1值差距明显（约0.0179）。对于准确率，第二的GRU配合注意力机制和第三的CNN配合注意力机制的数值接近，也和CNN有一定差距（约0.132）。对于正确率，第二为CNN配合注意力机制，数值明显低于CNN（差距约0.0102）。对于召回率，由GRU配合注意力机制、BiGRU配合注意力机制、BiLSTM配合注意力机制并排第二，与CNN的召回率差距明显（约0.0219）。

另外，虽然添加注意力机制对CNN的性能依然没有正面作用，但GRU，BiGRU和BiLSTM在添加注意力机制后都有较明显的提升，显示在特定情况下递归神经网络配合注意力机制能加建模能力，其关键在于注意力机制的原理是否与识别该特定语言特征相符。

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{\linewidth}
  \caption{面向“开心”、“悲伤”和“愤怒”的三分类器模型性能}
  \label{tab:exp_context_emo_tri_result}
    \begin{tabularx}{\linewidth}{X|llll}
    \toprule[1.5pt]
    & 准确率 & 正确率 & 召回率 & F1值 \\
    \hline
    CNN & \bf 0.9507 (1) & \bf 0.9454 (1) & \bf 0.9471 (1) & \bf 0.9462 (1) \\ % f_tri_cnn_ek_1554620372
    CNN+注意力机制 & 0.9351 (3) & 0.9352 (2) & 0.9215 (5) & 0.9283 (2) \\ % f_tri_cnn_ek_1554620395
    \hline
    GRU & 0.9315 (6) & 0.9278 (4) & 0.9142 (9) & 0.9210 (6) \\ % f_tri_gru_ek_1554576049
    GRU+注意力机制 & 0.9375 (2) & 0.9303 (3) & 0.9252 (2) & 0.9277 (3) \\ % f_tri_gru_ek_1554612493
    \hline
    BiGRU & 0.9303 (7) & 0.9212 (8) & 0.9179 (7) & 0.9196 (8) \\ % f_tri_bgru_ek_1554576063
    BiGRU+注意力机制 & 0.9339 (4) & 0.9235 (6) & 0.9252 (2) & 0.9243 (5) \\ % f_tri_bgru_ek_1554612494
    \hline
    LSTM & 0.9291 (8) & 0.9229 (7) & 0.9179 (7) & 0.9204 (7) \\ % f_tri_lstm_ek_1554575910
    LSTM+注意力机制 & 0.9279 (9) & 0.9180 (9) & 0.9197 (6) & 0.9189 (9) \\ % f_tri_lstm_ek_1554612497
    \hline
    BiLSTM & 0.9279 (9) & 0.9176 (10) & 0.9142 (9) & 0.9159 (10) \\ % f_tri_blstm_ek_1554575896
    BiLSTM+注意力机制 & 0.9339 (4) & 0.9269 (5) & 0.9252 (2) & 0.9260 (4) \\ % f_tri_blstm_ek_1554612490
    \bottomrule[1.5pt]
    \end{tabularx}
  \end{minipage}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{img/exp_context_emo_tri_result_bar.png}
  \caption{面向“开心”、“悲伤”和“愤怒”的三分类器模型性能}
  \label{fig:exp_context_emo_tri_result_bar}
\end{figure}

\subsubsection{面向“其他”和“不是其他”二分类的模型性能分析}
\label{sssec:exp_context_emo_b_base}

对于面向三轮对话的“其他”和“不是其他”二分类问题，表~\ref{tab:exp_context_emo_b_result}和图~\ref{fig:exp_context_emo_b_result_bar}显示不同卷积神经网络和迭归神经网络在测试集上能达到的性能。注意表中的正确率、召回率、F1值同样对应“不是其他”一类的指标。

对于F1值，CNN达到最高数值的0.7571，第二为GRU配合注意力机制，第三为BiGRU配合注意力机制，两者的F1值和CNN的差距都较大（0.01以上）。对于准确率和正确率，均由GRU配合注意力机制达到最好的性能（数值分别为0.9230和0.7343），第二为CNN，准确率和前者接近，但正确率差距较明显（0.0232），第三为BiGRU配合注意力机制。对于召回率，则是GRU的性能最佳（0.8233），第二的LSTM和前者的差距明显（0.0108）。

总的来说，CNN同时在四项指标上达到靠前的性能，GRU配合注意力机制也在三项指标上达到较好的性能，但召回率要远低于CNN（差距为0.0493），故对于面向三轮对话的“其他”和“不是其他”二分类问题，依然是CNN的整体建模能力最好。

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{\linewidth}
  \caption{面向“其他”和“不是其他”的二分类模型性能}
  \label{tab:exp_context_emo_b_result}
    \begin{tabularx}{\linewidth}{X|llll}
    \toprule[1.5pt]
    & 准确率 & 正确率 & 召回率 & F1值 \\
    \hline
    CNN & 0.9227 (2) & 0.7202 (2) & 0.7981 (3) & \bf 0.7571 (1) \\ % f_b_cnn_ek_1554620963
    CNN+注意力机制 & 0.9116 (7) & 0.6885 (5) & 0.7572 (9) & 0.7212 (8) \\ % f_b_cnn_ek_1554620537
    \hline
    GRU & 0.9074 (9) & 0.6536 (9) & \bf 0.8233 (1) & 0.7287 (6) \\ % f_b_gru_ek_1554547645
    GRU+注意力机制 & \bf 0.9230 (1) & \bf 0.7434 (1) & 0.7488 (10) & 0.7461 (2) \\ % f_b_gru_ek_1554561028
    \hline
    BiGRU & 0.9134 (4) & 0.6824 (6) & 0.7981 (3) & 0.7357 (4) \\ % f_b_bgru_ek_1554547845
    BiGRU+注意力机制 & 0.9152 (3) & 0.6907 (3) & 0.7945 (6) & 0.7390 (3) \\ % f_b_bgru_ek_1554561013
    \hline
    LSTM & 0.9011 (10) & 0.6347 (10) & 0.8125 (2) & 0.7127 (10) \\ % f_b_lstm_ek_1554549276
    LSTM+注意力机制 & 0.9121 (6) & 0.6895 (4) & 0.7608 (8) & 0.7234 (7) \\ % f_b_lstm_ek_1554554626
    \hline
    BiLSTM & 0.9089 (8) & 0.6708 (8) & 0.7788 (7) & 0.7208 (9) \\ % f_b_blstm_ek_1554549287
    BiLSTM+注意力机制 & 0.9131 (5) & 0.6814 (7) & 0.7969 (5) & 0.7346 (5) \\ % f_b_blstm_ek_1554553473
    \bottomrule[1.5pt]
    \end{tabularx}
  \end{minipage}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{img/exp_context_emo_b_result_bar.png}
  \caption{面向“其他”和“不是其他”的二分类模型性能}
  \label{fig:exp_context_emo_b_result_bar}
\end{figure}

\subsubsection{面向三轮对话的情感识别系统的性能分析}

经过前面各章节的分析，我们已经对各个子分类问题中不同模型的性能有大致了解，接下来我们将基于子分类器实现面向三轮对话的情感识别系统，并和比赛SemEval-2019任务三的参赛系统比较来评估我们系统的性能水平。

按照章节~\ref{sec:exp_context_emo_framework}，我们的情感识别系统涉及三个子分类问题。对于和原问题相同的情感四分类，根据章节~\ref{sssec:exp_context_emo_0_base}的实验结果，我们采用CNN模型作为第一组分类器。对于面向“开心”、“悲伤”和“愤怒”的三分类问题，按照章节~\ref{sssec:exp_context_emo_tri_base}的实验结果，我们同样选用CNN作为第二组分类器的模型。对于面向“其他”和“不是其他”的二分类问题，按照章节~\ref{sssec:exp_context_emo_tri_base}的实验结果，我们采用GRU配合注意力机制作为第三组分类器的模型。按照章节~\ref{ssec:exp_context_emo_model_training}，我们基于选定的模型分别为每个分类器组训练5个分类器。最后按照章节~\ref{sec:exp_context_emo_framework}中的设计的流程，经过各个组的投票结果逐步调整预测结果，最终得出三轮对话中最后一轮所表达的情感类别。对于系统中对第二、三个分类器组需要配置的与置信度相关的参数$thr_2$和$thr_3$，我们均设置为3，即完全相信第二、三个分类器组中过半数的投票结果。

表~\ref{tab:exp_context_emo_other_comp}显示我们的系统和SemEval-2019任务三其他参赛系统在测试集上最后一次提交的性能。注意表中的F1值为
针对“开心”、“悲伤”和“愤怒”的指标，即章节~\ref{ssec:exp_context_emo_eval_metric}中定义的$F_\mu$。在SemEval-2019任务三的最终测试阶段，参赛系统共165个，表中仅显示排名前10（按照F1值排名）的参赛系统，其中队伍名称为THU\_HCSI对应我们当时提交的系统，排名第8。

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{0.6\linewidth}
  \caption{SemEval-2019任务三前十名参赛系统性能} % 总参赛队伍165
  \label{tab:exp_context_emo_other_comp}
    \begin{tabularx}{\linewidth}{c|X|c}
    \toprule[1.5pt]
    排名 & 队伍名称 & F1值 \\
    \hline
    1 & PingAn GammaLab & 0.7959 \\
    2 & (无) & 0.7947 \\
    3 & NELEC & 0.7765 \\
    4 & SymantoResearch & 0.7731 \\
    5 & ANA & 0.7709 \\
    6 & CAiRE\_HKUST & 0.7677 \\
    7 & SNU\_IDS & 0.7661 \\
    8 & \bf THU\_HCSI & 0.7616 \\
    9 & (无) & 0.7608 \\
    10 & YUN-HPCC & 0.7588 \\
    \bottomrule[1.5pt]
    \end{tabularx}
  \end{minipage}
\end{table}

另外，为了分析系统中每一步决策带来的影响，我们观察了系统中各个中间结果在测试集上的性能。以下的系统由重新训练的子分类器组成，按照章节~\ref{ssec:exp_context_emo_model_training}的描述，子分类器的训练存在随机性，故和参赛系统有所不同，但在测试集上的F1值接近原系统的性能。

表~\ref{tab:exp_context_emo_ensemble_result}中第一行“中间结果I”对应直接由一组情感四分类器（第一个分类器组）进行多数投票的识别结果。第二行“中间结果II”是基于“开心”、“悲伤”和“愤怒”三分类器组（第二个分类器组）的投票对被判定为
这三个类别之一的样本重新进行分类的识别结果，可见四项指标都有所提升。再对比中间结果I和中间结果II的混淆矩阵（分别对应表~\ref{tab:exp_context_emo_conf_mat_1}和表~\ref{tab:exp_context_emo_conf_mat_2}）可以发现4个样本的识别结果被正确修正，2个“愤怒”的样本被误判为“悲伤”，这显示了即使引入阈值$thr_2$来评估投票的可信度，由子分类器之间投票得出的识别结果依然会存在判断出错的情况，但由于第二组的子分类器在“开心”、“悲伤”和“愤怒”三分类问题上的识别能力比第一组的四分类器更好，整体上还是对系统的识别性能有正面影响。

表中最底一行的“最终结果”是基于“其他”和“不是其他”的二分类器组（第三个分类器组）的投票结果尝试召回更多“其他”的样本，可见除了召回率有稍微下降，其他三项指标都有所提升，
虽然准确率只稍微上升，但正确率的明显提升大大提高了最终的F1值。

再对比中间结果II和最终结果的混淆矩阵（分别对应表~\ref{tab:exp_context_emo_conf_mat_2}和表~\ref{tab:exp_context_emo_conf_mat_3}）可以发现11个“其他”的样本被正确召回，间接提高了“开心”、“悲伤”和“愤怒”的正确率$P_\mu$，但同时误判了1个原本正确的样本，故召回率$R_\mu$下降。同样地第三组分类器在引入阈值$thr_3$后依然会为识别结果带来错误的修改，但被正确召回的样本比错误的多，整体上对系统的识别结果也是起着正面的作用。

接下来，我们再分析一下从原本的四分类问题中提取出面向“开心”、“悲伤”和“愤怒”三分类以及面向“其他”和“不是其他”二分类这两个子分类问题的合理性。首先对于面向“开心”、“悲伤”和“愤怒”的三分类问题，参考章节\ref{sssec:exp_context_emo_tri_base}
可以发现我们的模型在该子问题上有很好的区分能力（F1值达到0.9462），其数值明显高于原本的四分类问题（对比章节\ref{sssec:exp_context_emo_0_base}
中最高的F1值为0.7437），可见在引入类别“其他”后对F1值有较大影响，
一方面是数据量的增加，另一方面说明模型同时区分“其他”和另外三个类别存在较明显的困难。另外，回顾章节\ref{sssec:exp_context_emo_0_base}、\ref{sssec:exp_context_emo_tri_base}和\ref{sssec:exp_context_emo_b_base}可以注意到前两个子问题中整体性能最好的是CNN，而后者整体性能最好的是GRU配合注意力机制，证明了“其他”和另外三个类别背后的数学模型不同，因此在第二步中我们仅考虑面向“开心”、“悲伤”和“愤怒”的三分类问题，以改善这三个类别之间的识别结果。然后在第三步中我们选择以不同的模型来识别出原本没有被召回的“其他”的样本。

对于为什么只召回“其他”的样本，而没有反过来召回“不是其他”的样再进行三分类，这依然和核心评价指标以及各类别样本量的分布有关。“其他”的样本量在测试上明显多于另外三个类别的样本量，
而提高另外三个类别的召回率的同时也会把较多“其他”的样本误判为这三个类别之一，这就导致正确率$P_\mu$的下降显着大于召回率$R_\mu$，从而导致核心指标$F_\mu$下降。而相反地从原本被识别为“开心”、“悲伤”和“愤怒”的样本中召回“其他”的样本，虽然会把部分原本识别正确的样本误判为“其他”，但会有较大概率召较多“其他”的样本，同时显着提升正确率$P_\mu$。因此我们选择召回更多“其他”的样本作为第三步的核心目标，而实验结果验证了我们的判断。

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{0.6\linewidth}
  \caption{我们的多步决策识别系统的中间结果和最终结果在测试集上的性能}
  \label{tab:exp_context_emo_ensemble_result}
    \begin{tabularx}{\linewidth}{X|cccc}
    \toprule[1.5pt]
    & 准确率 & 正确率 & 召回率 & F1值 \\
    \hline
    中间结果I & 0.9278 & 0.7360 & 0.7740 & 0.7545 \\
    中间结果II & 0.9281 & 0.7383 & \bf 0.7764 & 0.7569 \\
    \hline
    最终结果 & \bf 0.9299 & \bf 0.7474 & 0.7752 & \bf 0.7611 \\ 
    \bottomrule[1.5pt]
    \end{tabularx}
  \end{minipage}
\end{table}

\begin{table}[]
  \centering
  \begin{minipage}[t]{0.54\linewidth}
  \caption{
    \label{tab:exp_context_emo_conf_mat_1}
    测试集上中间结果I对应的混淆矩阵
  }
  \begin{tabularx}{\linewidth}{c|c|cccc}
  \toprule[1.5pt]
  \multicolumn{2}{c|}{\multirow{2}{*}} & \multicolumn{4}{c}{预测标签}    \\
  \cline{3-6} 
  \multicolumn{2}{c|}{}
    & 其他 & 开心 & 悲伤 & 愤怒  \\
  \hline
  \multirow{4}{*}{真实标签}
    & 其他 & 4467 & 65 & 57 & 88 \\
    & 开心 & 82 & 196 & 4 & 2 \\
    & 悲伤 & 38 & 2 & 201 & 9 \\
    & 愤怒 & 47 & 1 & 3 & 247 \\
  \bottomrule[1.5pt]
  \end{tabularx}
  \end{minipage}
\end{table}

\begin{table}[]
  \centering
  \begin{minipage}[t]{0.54\linewidth}
  \caption{
    \label{tab:exp_context_emo_conf_mat_2}
    测试集上中间结果II对应的混淆矩阵
  }
  \begin{tabularx}{\linewidth}{c|c|cccc}
  \toprule[1.5pt]
  \multicolumn{2}{c|}{\multirow{2}{*}} & \multicolumn{4}{c}{预测标签}    \\
  \cline{3-6} 
  \multicolumn{2}{c|}{}
    & 其他 & 开心 & 悲伤 & 愤怒  \\
  \hline
  \multirow{4}{*}{真实标签}
    & 其他 & 4467 & 65 & 60 & 85 \\
    & 开心 & 82 & 197 & 4 & 1 \\
    & 悲伤 & 38 & 1 & 204 & 7 \\
    & 愤怒 & 47 & 1 & 5 & 245 \\
  \bottomrule[1.5pt]
  \end{tabularx}
  \end{minipage}
\end{table}

\begin{table}[]
  \centering
  \begin{minipage}[t]{0.54\linewidth}
  \caption{
    \label{tab:exp_context_emo_conf_mat_3}
    测试集上最终结果对应的混淆矩阵
  }
  \begin{tabularx}{\linewidth}{c|c|cccc}
  \toprule[1.5pt]
  \multicolumn{2}{c|}{\multirow{2}{*}} & \multicolumn{4}{c}{预测标签}    \\
  \cline{3-6} 
  \multicolumn{2}{c|}{}
    & 其他 & 开心 & 悲伤 & 愤怒  \\
  \hline
  \multirow{4}{*}{真实标签}
    & 其他 & 4478 & 60 & 57 & 82 \\
    & 开心 & 82 & 197 & 4 & 1 \\
    & 悲伤 & 39 & 1 & 203 & 7 \\
    & 愤怒 & 47 & 1 & 5 & 245 \\
  \bottomrule[1.5pt]
  \end{tabularx}
  \end{minipage}
\end{table}

\subsection{错误分析}
\label{ssec:exp_context_emo_error_analysis}

本节中，我们将对系统错误识别的样本进行观察，分析其中的原因，从而对问题有更进入的了解以及下一步的改进方向。以下使用的例子均参照表~\ref{tab:semeval_2019_task3_error}。

\begin{itemize}

\item {\bf 短语情感倾向识别}。参考例子1，第一轮中用户甲的“in mood”表示心情愉快，属于正向情感，第三轮中的“yeah”偏中性，按照章节~\ref{ssec:exp_context_emo_multi_turn_analyse}，应该得出样本情感标签为“开心”。然而“in mood”在训练集中主要以“not in mood”出现，且这些的样本标签都是“悲伤”，显然系统未能正确识别“in mood”本身的情感倾向导致了识别错误。另外对于在训练集上没有出现过的短语也会有相同的问题，较直观的做法是引入语言知识，优先对这些基于人工规则进行匹配的样本进行识别，再将规则无法匹配的样本交由机器学习的方法进行深层次的建模。这种思想也对应我们的多步决策系统框架，只是其中的决策不再限于使用机器学习的方法。

\item {\bf 对于同时出现多种情感的处理}。参考例子2，第三轮中用户甲的发言在字面上包含两种情感，首先是“Haha”表达偏向“开心”的情感，“Bite me!\includegraphics[height=1.5\fontcharht\font`\B]{img/emoji/speechless.png}”则带有鄙视和不满的意思，倾向于“悲伤”。按照章节~\ref{ssec:exp_context_emo_multi_turn_analyse}的分析，应以后半“悲伤”的情感为主。然而我们选用的CNN模型中，CNN的序列输出以最大池整合为一个固定长度的向量，即模型没有考虑情感出现的先后而直接保留了字面上情感最强烈的内容，这也表现出了人工神经网络架构对数据拟合的影响。

\item {\bf 理解比喻修辞}。参考例子3，用户甲在第一轮和第三轮中都在以比喻的修辞辱骂用户乙，然而系统从字面意思上未能识别出其情感倾向于“愤怒”。首先，在训练集上确实存在“be a pig”且大部分的标注都为“愤怒”，理论上机器学习有学习出“be a pig”带有表达“愤怒”的倾向。但数据中没有包含“be a dog”的样本，那么如果算法未能关联“pig”和“dog”就不可能识别出“be a pig”的倾向。而从语言的角度来看，解决这个问题的本质是识别出作为修辞手法的比喻的使用，并且理解其想表达的意思，这就回归到上一章节中对修辞手法进行建模的问题。

\item {\bf 语料中可能存在带噪音的标注}。参考例子4，第三轮中用户甲的发言仅包含两个大笑的表情符“\includegraphics[height=1.5\fontcharht\font`\B]{img/emoji/lol.png}”，而前两轮的文本内容则偏向中性，我们有理由认为这个样本应该标记为“开心”，然而组织者给出的标注为“其他”。再参考例子5，第三轮中用户甲的发言同样仅包含大笑的表情符“\includegraphics[height=1.5\fontcharht\font`\B]{img/emoji/lol.png}”，而前两轮的文本内容同样偏向中性，但标注为“开心”。假如我们对例子3的情感判断正确，那就说明官方提供的标注中存在噪音，这在意图识别相关的研究中其实属于普遍现象，除了因为人工标注过程中会出现人为错误以外，还因为人工判断会存在不可避免的主观性。

\end{itemize}


\begin{table}[]
  \centering
  \begin{minipage}[t]{0.7\linewidth}
  \caption{
    \label{tab:semeval_2019_task3_error}
    测试集中被系统误判的样本例子
  }
  \begin{tabularx}{\linewidth}{c|c|l}
  \toprule[1.5pt]

   编号 & 情感类别 & 对话    \\
  \hline
  \multirow{3}{*}{1} & \multirow{3}{*}{开心} 
    &   （第一轮）用户甲: I'm in mood \\
    & & （第二轮）用户乙: ya need a hug ? :-) \\
    & & （第三轮）用户甲: yeah \\
  \hline
  \multirow{3}{*}{2} & \multirow{3}{*}{悲伤} 
    &   （第一轮）用户甲: I am \\
    & & （第二轮）用户乙: in your dreams \\
    & & （第三轮）用户甲: Haha Bite me! \includegraphics[height=1.5\fontcharht\font`\B]{img/emoji/speechless.png}\includegraphics[height=1.5\fontcharht\font`\B]{img/emoji/speechless.png}\includegraphics[height=1.5\fontcharht\font`\B]{img/emoji/speechless.png} \\
  \hline
  \multirow{3}{*}{3} & \multirow{3}{*}{愤怒} 
    &   （第一轮）用户甲: You are pig \\
    & & （第二轮）用户乙: so are you \\
    & & （第三轮）用户甲: You are dog \\
  \hline
  \multirow{3}{*}{4} & \multirow{3}{*}{其他} 
    &   （第一轮）用户甲: Wat u wanna knw? \\
    & & （第二轮）用户乙: i knw nothin :P \\
    & & （第三轮）用户甲: \includegraphics[height=1.5\fontcharht\font`\B]{img/emoji/lol.png}\includegraphics[height=1.5\fontcharht\font`\B]{img/emoji/lol.png} \\
  \hline
  \multirow{3}{*}{5} & \multirow{3}{*}{开心} 
    &   （第一轮）用户甲: You cannot see my hair \\
    & & （第二轮）用户乙: I'm in your closet \\
    & & （第三轮）用户甲: \includegraphics[height=1.5\fontcharht\font`\B]{img/emoji/lol.png} \\
  \bottomrule[1.5pt]
  \end{tabularx}
  \end{minipage}
\end{table}

\section{本章小结}

在本章中我们研究面向三轮对话的情感识别，基于国际比赛SemEval-2019任务三的设置和提供的数据集进行实验。我们提出了一个多步决策的情感识别系统，从原始问题中选出三个子分类问题，分别选择合适的模型训练出对应的子分类器组，最后透过多步决策融合这些模型的识别结果。参赛结果显示我们系统的性能在165个参赛系统中排名前十。另外我们观察了系统中每步决策如何对整体识别性能带来影响，从中分析我们选出各个子分类问题的合理性，并强调对于多分类问题，各类别的样本量分布和系统在不同评价指标上的表现密切相关，对两者之间的关系进行分析有助于选择合适的子分类问题，并针对特定的评价指标进行优化。

