\chapter{基于多分类器分层的微博反讽识别}
\label{cha:exp_irony_det}

\section{本章引论}

社交媒体的发展对语言体系带来了很大的影响，网络上不断出现新的用词和句式，语言的表达方式越来越丰富，同时变得越来越复杂，这也是面向社交文本的情感识别的难点之一。而其中，反讽是在网络上常见的语言修辞手法之一, 它在情感识别的研究当中有着重要的地位。Henry Watson Fowler在《The King's English》一书中指出反讽的使用使得“表面意思和实际意思不同”。譬如一个人说“你这想法真有创意”，在字面意思上是对另一个人的赞同，但在特定背景下，如果紧接一句“你真相信这能实现吗”，那么发言者实际上可能暗示这个想法无法落地，表面上称赞为“有创意”，其实在暗示这种想法不切实际。这在情感识别当中尤其重要，无视反讽的使用会导致对内容的错误理解，因此反讽识别一直是和情感识别紧密相关的研究课题之一。

根据Joshi等人\cite{joshi2017automatic}对近年相关研究的总结，反讽识别可以大致分成基于规则的方法和基于机器学习的方法两种。基于规则的方法透过人工找出反讽修辞的语言规律，设计出对应的匹配规则，然后在识别过程中，若文本中的内容符合匹配规则，则认为它属于对应的反讽类别。和机器学习方法对比，基于规则的方法优点在于无需模型训练，但要求研究员在语言知识上对反讽有充分的理解，设计的匹配规则对语言模式的复盖程度决定了算法的识别能力。而随着近年深度学习快速发展，一些研究更关注词嵌入向量的使用以及人工神经网络的设计。

在反讽识别的研究中，各类别样本分布不均匀是一个备受关注的问题。虽然反讽是较常见的修辞手法，但在现实场景中，使用反讽的情况还是占少数。对于反讽的细分类别，其样本分布不均匀的情况则更为明显。但倾向于把样本识别为占比较大的类别是目前机器学习算法的通病，这也是其他研究领域在现实应用场景中会出现的问题。针对数据不均匀的情况，主流的解决方法包括欠采样、过采样、数据增强等。虽然这些方法在语音和图像领域使用较广，原理较直观而实现上也较简单，但在自然语言处理领域，因为要考虑文本的语义和语法，目前还没有较成熟的做法。为此我们提出了一种多分类器分层识别算法，有别于从数据的采样或对数据的加工入手，我们把多分类问题拆解成多个子分类问题的叠加，再经由回答每个子分类问题来得出原本多分类问题的识别结果。透过拆解出子分类问题，使得在局部调整算法的识别性能成为可能。

国际比赛SemEval-2018的任务三\cite{van2018semeval}旨在促进英语微博中的反讽识别研究，其中包含了两个子任务。子任务一是二分类的反讽识别，需要识别微博是否有使用反讽。子任务二是四分类的反讽识别，是子任务一的拓展，除了判断微博是否包含反讽，原本的反讽类别再细分成三个类别：基于相反语义的反讽、情景反讽、其他反讽。本章节将基于SemEval-2018的任务三进行实验，并透过和其他参赛系统进行比较来评估我们算法的性能。

本章的内容安排如下。章节\ref{sec:exp_irony_det_format}会首先给出当前问题的形式化表示。章节\ref{sec:exp_irony_det_data}再对具体实验数据进行观察，分析各个反讽类别样本的特征以及微博文本的特征等。章节\ref{sec:exp_irony_det_framework}将给出针对当前问题提出的多分类器分层识别算法。最后在章节\ref{sec:exp_irony_det_exp}给出实验的细节以及对实验结果的分析。

\section{形式化表示}
\label{sec:exp_irony_det_format}

本章研究了面向微博的反讽识别，以下给出此问题的形式化表示。给定一个反讽类别集合$C$，对于微博集合$T$中的任意一条微博$t$，它属于唯一一种反讽类别$c \in C$。又给定一个词集合$W$，微博$t$经过文本预处理后可以表示为一个长度为$L$的词序列 $w = <w_1, w_2, ..., w_L>, w_i \in W, i \in [1, L]$。因为没有引入上下文信息，所以背景$B$在模型中忽略。那么目标就是找出一个映射关系$f$，使得$c=f(w)$。

\section{实验数据}
\label{sec:exp_irony_det_data}

实验采用SemEval-2018的任务三提供的数据集，其中的语料收集自微博平台Twitter上发布于2014年至2015年之间的微博，再由人工标注得出每条微博的反讽类型。该比赛的两个子任务均采用了相同的语料，但标注稍有不同。

\subsection{样本分布}

子任务一是二分类的反讽识别，需要识别微博是否有使用反讽，各类别的样本分布如表\ref{tab:semeval_2018_task3_A_data}所示，表\ref{tab:semeval_2018_task3_A_sample}为语料中两个类别的例子。可以看出“没有反讽”和“带有反讽”两个类别的样本在训练集上大致比例为1:1，在测试集上两个类别的分布大致为3:2。

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{0.7\linewidth} % 如果想在表格中使用脚注，minipage是个不错的办法
  \caption{反讽识别子任务一各类别样本数量分布}
  \label{tab:semeval_2018_task3_A_data}
    \begin{tabularx}{\linewidth}{X|XX}
    \toprule[1.5pt]
    数据集 & 没有反讽 & 带有反讽 \\  
    \hline
    训练集 & 1923 & 1911 \\
    测试集 & 473  & 311 \\
    \bottomrule[1.5pt]
    \end{tabularx}
  \end{minipage}
\end{table}

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{0.8\linewidth} % 如果想在表格中使用脚注，minipage是个不错的办法
  \caption{反讽识别子任务一样例}
  \label{tab:semeval_2018_task3_A_sample}
  \begin{tabularx}{\linewidth}{c|l|X}
    \toprule[1.5pt]
    编号 & 类别 & 例子 \\
    \hline
    1 & 没有反讽 & Had no sleep and have got school now \#not happy \\
    2 & 带有反讽 & I just love when you test my patience!! \#not \\
    \bottomrule[1.5pt]
  \end{tabularx}
  \end{minipage}
\end{table}

子任务二是四分类的反讽识别，是子任务一的拓展，除了判断微博是否包含反讽，原本“带有反讽”的样本再细分成三个类别：基于相反语义的反讽（为简化，在以下图表中简称为“反义反讽”）、情景反讽、其他反讽。各类别的数据分布如表\ref{tab:semeval_2018_task3_B_data}所示，表\ref{tab:semeval_2018_task3_B_sample}为语料中各反讽类别的例子。可见“带有反讽”一类细分出的三个反讽类别在样本分布上有明显的不均匀，“基于相反语义的言语反讽”占了其中一半以上，“情景反讽”、“其他反讽”的样本量则相对较少。

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{\linewidth} % 如果想在表格中使用脚注，minipage是个不错的办法
  \caption{反讽识别子任务二各类别样本数量分布}
  \label{tab:semeval_2018_task3_B_data}
    \begin{tabularx}{\linewidth}{X|XXXX}
    \toprule[1.5pt]
    数据集 & 没有反讽 & 反义反讽 & 情景反讽 & 其他反讽\\  
    \hline
    训练集 & 1923 & 1390 & 316  & 205 \\
    测试集 & 473  & 164  & 85  & 62 \\
    \bottomrule[1.5pt]
    \end{tabularx}
  \end{minipage}
\end{table}

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{\linewidth} % 如果想在表格中使用脚注，minipage是个不错的办法
  \caption{反讽识别子任务二样例}
  \label{tab:semeval_2018_task3_B_sample}
  \begin{tabularx}{\linewidth}{c|l|X}
    \toprule[1.5pt]
    编号 & 类别 & 微博 \\
    \hline
    1 & 没有反讽 & Had no sleep and have got school now \#not happy \\
    2 & 反义反讽 & I really love this year’s summer; weeks and weeks of awful weather \\
    3 & 情景反讽 & Most of us didn’t focus in the \#ADHD lecture. \#irony \\
    4 & 其他反讽 & @someuser Yeah keeping cricket clean, that's what he wants \#Sarcasm \\
    \bottomrule[1.5pt]
  \end{tabularx}
  \end{minipage}
\end{table}

\subsection{各反讽类别的语言特征}

比赛组织者对四种反讽类别给出了对应的说明。对“基于相反语义的反讽”，文本中存在某部分内容表达了可评估的情感极性，但整条微博实际上表达了相反的情感极性。如表\ref{tab:semeval_2018_task3_B_sample}中的例子2，“love”在字面意思上表达了正面的情感，但微博后半中“awful weather”提示实际情况引起了发言者的不适，发言者其实在表达对这个夏天坏天气的不满，这和“love”的正面情感恰恰相反。对于“情景反讽”，文本正描述某个场景，其中发生的事情和对该场景的预期不符。如表\ref{tab:semeval_2018_task3_B_sample}中的例子3，描述了一个参与讲座的场景，但“我们”并没有专注于这场讲座，和“参与者应该专注于讲座内容”的预期相反。对于“其他反讽”，文本表达了讽刺的意思，但文本的字面意思和发言者表达的意思之间并不存在情感极性的反差。如表\ref{tab:semeval_2018_task3_B_sample}中的例子4，发言者表示某人想要保持蟋蟀干净，字面上并不存在情感极性，但在句子后的井号标签提示了发言者表达了讽刺，认为“保持蟋蟀干净”是一样莫名奇妙的事情。最后是“没有反讽”一类，对于明显不可能包含反讽的文本，或者在背景信息不足的情况下不能确认其包含反讽的文本均属于这一类。

\subsection{文本长度}

我们对数据集的文本进行分词后统计了各类别样本的单词数量分布，以下简称为文本长度。表\ref{fig:semeval2018_task3_train_class_len}和表\ref{fig:semeval2018_task3_test_class_len}分别显示了训练集和测试集上各类别样本的文本长度。综合先见样本的文本长度不超过50，样本的平均文本长度约为20个词。根据表\ref{fig:semeval2018_task3_train_class_len}可以看出“情景反讽”的样本整体的文本长度较其他类别的长，“没有反讽”和“基于相反语义的反讽”在文本长度分布上没有明显区别，“其他反讽”整体的文本长度则略高于前两者。再观察表\ref{fig:semeval2018_task3_test_class_len}，同样地“没有反讽”和“基于相反语义的反讽”在文本长度分布上没有明显区别，“情景反讽”的文本长度略长于前两者，但不如训练集上明显。

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{img/semeval2018_task3_train_class_len.png}
  \caption{反讽识别训练集上各类别文本长度分布}
  \label{fig:semeval2018_task3_train_class_len}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{img/semeval2018_task3_test_class_len.png}
  \caption{反讽识别测试集上各类别文本长度分布}
  \label{fig:semeval2018_task3_test_class_len}
\end{figure}

\subsection{文本特征}
\label{ssec:exp_irony_det_data_text}

另外我们注意到语料中存在微博平台Twitter上特有的文本特征，出现频率较高的特征如下：

\begin{itemize}

\item 用户标签“@someuser”。对应微博上的一个用户，使用场景包括以下两种。一是作为句子中的名词使用，二是添加在句前或句末，用于提示该用户与本条微博有关，不具有语法作用。

\item 井号标签“\#something”。使用场景大致分为以下两种。一是作为句子中的一部分，如“I \#do \#like \#it”，去除井号后满足正规的英语用法，此时井号标签的作用是对内容的强调。另一种是出现在句末，用于提示微博内容与标签对应内容相关，如句末出现“\#sarcasmtweet”则是明示讽刺。

\item 网站链接。在微博平台上支持附加一个网站链接，其中平台对链接进行了统一处理，在语料库中网站链接均形如“http://t.co/***”或“https://t.co/***”。

\item 转发标记“RT”（retweet）。当用户转发一条微博并添加个人评论时，平台会自动在个人评论后附加转发的微博原文并以“RT”隔开。

\item 一些在社交媒体平台上常见的、有别于正规英语的用法，如拼写错误、缩略词、全大写字母的单词、表情符等，可以参考章节\ref{ssec:text_preprocess}描述的例子。

\end{itemize}


\section{框架设计}
\label{sec:exp_irony_det_framework}

对于任务一，由于是二分类问题，我们只考虑使用一组二分类器进行多数投票得出最终的预测结果，判断微博文本是否采用了反讽修辞。

对于任务二，我们提出了一个多分类器分层识别算法。对于原本的反讽四分类问题，它被拆解成了以下四个子分类问题的叠加：

\begin{enumerate}

\item 原本的反讽四分类问题。
\item “没有反讽”和“基于相反语义的反讽”二分类。
\item “没有反讽”和“情景反讽”二分类。
\item “没有反讽”和“其他反讽”二分类。

\end{enumerate}

对于每个子分类问题，我们分别准备其对应的分类器组，依次命名为第一、第二、第三、第四组分类器，分别由$N_1$、$N_2$、$N_3$、$N_4$个分类器组成。那么对于一条待识别的微博，决策过程如下：

\begin{itemize}

\item 首先，由对应原四分类问题的第一组分类器进行多数投票，得出预测标签$Label^{1}_{MV}$，直接以它作为第一步的预测标签$Label_{I}$ 。以下把算法到这一步为止的判断结果称为中间结果I。

\item 第二步，由面向“没有反讽”和“基于相反语义的反讽”二分类的第二组分类器进行多数投票，得出预测标签$Label^{2}_{MV}$。若其中超过$thr_{2}$个分类器投票给$Label^{2}_{MV}$且第一步的预测标签$Label_{I}$为“没有反讽”或“基于相反语义的反讽”，则把预测标签修改为$Label^{2}_{MV}$，否则保持不变，以此得出第二步的预测标签$Label_{II}$。以下把算法到这一步为止的判断结果称为中间结果II。

\item 第三步，由面向“没有反讽”和“情景反讽”二分类的第三组分类器进行多数投票，得出预测标签$Label^{3}_{MV}$。若其中超过$thr_{3}$个分类器投票给$Label^{3}_{MV}$且第二步的预测标签$Label_{II}$为“没有反讽”或“情景反讽”，则把预测标签修改为$Label^{3}_{MV}$，否则保持不变，以此得出第三步的预测标签$Label_{III}$。以下把算法到这一步为止的判断结果称为中间结果III。

\item 最后一步，由面向“没有反讽”和“其他反讽”二分类的第四组分类器进行多数投票，得出预测标签$Label^{4}_{MV}$。若其中超过$thr_{4}$个分类器投票给$Label^{4}_{MV}$且第三步的预测标签$Label_{III}$为“没有反讽”或“其他反讽”，则把预测标签修改为$Label^{4}_{MV}$，否则保持不变，以此得出第四步的预测标签$Label_{IV}$，同时作为整个算法对该微博最终的反讽识别结果。

\end{itemize}

整个决策过程可以分成两大部分。第一部分的目的是初步完成对微博的四分类反讽识别，对应上述四步决策中的第一步。第二部分的目的是基于第一部分的初步识别结果逐步进行修正，每一步只关注一个子分类问题。对应上述四步决策中的后三步，每步只关注“没有反讽”和其中一个反讽子类的二分类问题，由一组专门的分类器给出子分类问题的识别结果，当新的识别结果充分可信则修改前一步得到的预测标签。在这里新识别结果的可信度由投票数决定，当多数票是由超过$thr$个分类器投票所得则认为它充分可信。

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\textwidth]{img/irony_det_system.pdf}
  \caption{面向四分类反讽识别的多分类器分层识别算法}
  \label{fig:irony_det_system}
\end{figure}

其中对于每个子分类问题，我们都采用了相同的模型框架，如图\ref{fig:irony_det_cls_framework}所示，每个子分类器的输入都是微博文本经过预处理后得到的词序列$\{w_i\}$，然后每个词替换成对应的词嵌入向量，作为特征编码器的输入。特征编码器的目的是把微博文本对应的词向量序列转换成固定长度的特征向量，作为其反讽属性相关的表示向量。

特征编码器首先由一层或多层卷积神经网络或迭归神经网络组成，但二维卷积神经网络和迭归神经网络的输出均为和输入序列等长度的向量序列，需要进一步结合整个向量序列的信息并转换成固定长度的向量。对于卷积神经网络，主流做法之一是采到最大池化层，分别取各特征位上的最大值。而对于迭归神经网络，主流做法之一是取序列的最后一个向量，在理论上迭归神经网络在最后一时刻的输出结合了所有输入的信息，另一种是采用注意力机制。

接下来，将微博的表示向量作为概率预测器的输入，概率预测器的目的是得出各个反讽类别的概率分布。此处概率预测器采用单层的全联接层，以$Softmax$作为激活函数得出概率分布，最后取概率最高者作为分类器对该条微博的预测结果。

考虑到对于不同反讽类别的语言特征不同，各个模型的建模能力也会有所不同。所以对于每个子分类问题，我们会分别比较各个模型的性能，以求在子分类问题上达到尽可能好的识别性能。

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{img/irony_det_cls_framework.pdf}
  \caption{反讽识别子分类器模型框架}
  \label{fig:irony_det_cls_framework}
\end{figure}

\section{实验与分析}
\label{sec:exp_irony_det_exp}

\subsection{数据预处理}
\label{ssec:exp_irony_det_text_preprocess}

基于章节\ref{ssec:exp_irony_det_data_text}中对样本文本的观察，我们依次采取了以下数据预处理手法：

\begin{itemize}

\item 对于不用的用户标签“@someuser”，假设具体的用户名不影响微博内容的反讽类别，故统一替换成“<user>”。

\item 对于井号标签“\#something”，将其替换成一个字符串序列“<hashtag>”、“something”、“</hashtag>”，此处“<hashtag>”表示井号标签的开始，“</hashtag>”表示井号标签的结束，原因在于Twitter平台上，井号标签可能由多个单词组成，如语料中出现的井号标签“\#SoCute”，应该分解成“so”、“cute”两个单词，而语料中多单词组成的井号标签普遍采用首字母大写示意，故可以简单完成分词，同时在前后添加“<hashtag>”和“</hashtag>”示意中间的内容属于同一个井号标签即可。

\item 对于全字母大写的文本段，在该段文本的前后添加“<allcap>”和“</allcap>”示意。如“YAYYYY”替换成序列“<allcap>”、“yayyyy”、“</allcap>”。

\item 对于重复次数大于等次三次的标点符号，以“<repeated>”示意，如“!!!”替换成序列“!”、“<repeated>”，表示“!”被多次重复，即时假设重复的具体次数和原微博的反讽类别无关。

\item 对于字母被故意重复的单词，以“<elongated>”示意，如“Noooooooo”替换成序列“No”、“<elongated>”，表示“No”中某一个或多个字母被多次重复，即假设被重复的字符和具体重复的次数和原微博的反讽类别无关。

\item 将数字串替换成“<num>”，将电话号码替换成“<phone>”，将日期和时间分别替换成“<date>”和“<time>”，将数字百分比替换成“<percentage>”，超链接替换成“<url>”，即假设其中的具体数值和原微博的反讽类别无关。

\item 对于由多个标点符号组成的表情符，将其替换成对应的情感标签，如将“:)”替换成“<happy>”，“:((”替换成“<sad>”。

\item 在完成以上处理后，对英文的大小写统一转换成小写。

\end{itemize}

以上功能基于第三方的英语文本处理工具\textit{ekphrasis}\footnote{https://github.com/cbaziotis/ekphrasis}完成，对于其中如何分词、如何识别电话号码和日期、以及颜文字到情感标签的详细映射关系列表，读者可以直接参考其代码实现和配置文件。

\subsection{评价指标}

按照国际比赛SemEval-2018任务三的设置，各个子任务均以F1值作为系统识别性能的主要评价指标。对于其中一个类别$c$的F1值，其定义如下：

\vspace{-8mm}
\begin{equation}
\vspace{-2mm}
  F_c = \frac{2 \times P_c \times R_c}{P_c + R_c} 
\end{equation}

其中 $P_c$ 为类别$c$的正确率，$R_c$ 为类别$c$的召回率，其定义如下：

\vspace{-8mm}
\begin{eqnarray}
\vspace{-2mm}
  P_c &=& \frac{TP_c}{TP_c + FP_c} \\
  R_c &=& \frac{TP_c}{TP_c + FN_c}
\end{eqnarray}

其中$TP_c$表示被系统预测为类别$c$，且真实标签为类别$c$的样本数量；$FP_c$表示被系统预测为类别$c$，但真实标签不是类别$c$的样本数量；$FN_c$表示被系统预测为不是类别$c$，但真实标签为类别$c$的样本数量。对于子任务一，系统性能以“带有反讽”一类样本的F1值为主要评估指标。对于子任务二，系统性能以各个类别的F1值的宏平均作为主要评价指标，即：

\vspace{-8mm}
\begin{equation}
\vspace{-2mm}
\begin{aligned}
  F_{macro} = \sum\limits_{c \in C}F_c
\end{aligned}
\end{equation}

此处$C$对应子任务二中四个类别组成的集合，即\{没有反讽，基于相反语义的反讽，情景反讽，其他反讽\}。在以下实验中，除了F1值、正确率和召回率，我们还会观察模型的准确率，其定义如下：

\vspace{-8mm}
\begin{equation}
\vspace{-2mm}
\begin{aligned}
  Acc &= \frac{\sum\limits_{c \in C} TP_c}{\sum\limits_{c \in C}(TP_c + FP_c)}
\end{aligned}
\end{equation}

其中$TP_c$和$FP_c$如前述的定义，而$C$在子任务一中对应两个类别组成的集合，即\{没有反讽，带有反讽\}。


\begin{table}[htb]
  \centering
  \begin{minipage}[t]{0.55\linewidth}
  \caption{模型训练参数}
  \label{tab:exp_irony_det_model_param}
    \begin{tabularx}{\linewidth}{X|l}
    \toprule[1.5pt]
    参数 & 数值 \\
    \hline
    词向量维数 & 300 \\
    RNN内各隐藏层神经元数量 & 150 \\
    CNN卷积核大小 & 5 \\
    CNN过滤器数量 & 128 \\
    注意力机制的隐藏层神经元数量 & 64 \\
    高斯噪音的标准方差 & 0.1 \\
    Dropout比例 & 0.5 \\
    学习率初始值 & 0.01 \\
    学习率衰减系数 & 0.9 \\
    L2正则项权重 & 0.2 \\
    训练的迭代次数 & 200 \\
    训练的批大小 & 100 \\
    \bottomrule[1.5pt]
    \end{tabularx}
  \end{minipage}
\end{table}

\subsection{模型训练}
\label{ssec:exp_irony_det_model_training}

对于每个子分类问题，分别从完整的训练数据和测试数据中筛选出对应类别的样本作为实验数据，并采用相同的方法进行模型训练，训练参数如表~\ref{tab:exp_irony_det_model_param}所示，另外采用了一些训练策略如下：

\begin{itemize}

\item 对于训练数据，分别从各个类别的样本中随机选出90\%的样本作为训练集，剩余10\%的样本作为验证集，以保留各个类别的样本分布。在每一轮模型参数调整后，计算各组模型参数在验证集上的F1值，经过有限轮迭代后，取在验证集上F1值最优的网络参数作为该分类器的参数，以此避免在训练数据上过拟合。

\item 由于算法中每个子分类问题由多个分类器经过多数投票给出识别结果，为了充分运用训练数据，在训练过程中每个分类器的验证集为独立随机筛选得出，一方面使得每个训练样本都有概率被用于某个分类器的模型训练，另一方面各个分类器的训练集不同，避免了对部分数据的过拟合。

\item 词嵌入层利用了章节\ref{sssec:embedding}中Baziotis等人\cite{baziotis2018ntua}提供的词嵌入模型，直接用于初始化词嵌入层的参数。而对于词嵌入模型中未被覆盖的单词，若它在至少2个训练样本中出现，则为其随机生成词向量。训练过程中不对词嵌入层的参数进行调整。

\item 在参数训练阶段，对词嵌入层输出的词向量序列添加高斯噪音。由于词嵌入算法在原理上使得意思相似的单词投影到词嵌入空间中距离相近的点上，高斯噪音的添加相当于把原本的单词替换成近义词，使得模型能更好地理解近义词构成的语言模式，另一方面缓解过拟合的问题。在验证阶段和测试阶段，高斯噪音的标准方差被调整为零，即不起作用。

\item 在参数训练阶段，在特征编码器和概率预测器之间添加了Dropout层，以概率$p_{Dropout}$将特征编码器得出特征向量上的各位数值置为零，并对没有被置零的各位数值乘以常量 $\frac{1}{1-p_{dropout}}$。在验证阶段和测试阶段，Dropout层不起作用。

\item 对于模型训练的损失函数，以权重$l_2$加入了概率预测器中全联接层的权重（不包括偏移量）的L2正则项。

\item 在面向“没有反讽”和“其他反讽”的二分类问题中，由于两个类别的样本数据差异较大（1923：205），当人工神经网络根据样本的误差透过反向传播进行学习时，如果所有样本的权重相同，模型会倾向于把所有样本判断为样本量够多的“没有反讽”。为此我们根据样本量的分布决定各个类别的样本的权重。如公式\ref{eq:class_weight}所示，其中$w_c$表示类别$c$对应每个样本的权重，$N$表示总的训练样本数，$C$表示该子分类问题的类别集合，此处即为\{没有反讽，其他反讽\}，$N_c$示类别$c$对应的训练样本数。

\end{itemize}

\vspace{-10mm}
\begin{equation}
\vspace{-2.5mm}
\begin{aligned}
    \label{eq:class_weight}
    w_c = \frac{N}{|C| \times N_c}
\end{aligned}
\end{equation}

\subsection{实验结果与分析}

对应章节~\ref{sec:global_framework}，实验分成两大部分。第一部分针对各个子分类问题进行研究，根据章节~\ref{sec:exp_irony_det_framework}，反讽识别算法涉及以下多个子分类问题：区分四个反讽类别的四分类问题、区分“没有反讽”和“基于相反语义的反讽”的二分类问题、区分“没有反讽”和“情景反讽”的二分类问题、区分“没有反讽”和“其他反讽”的二分类问题。对于每个子分类问题，我们基于章节~\ref{sec:exp_irony_det_framework}中提出的分类器模型框架进行实验，比较不同模型的建模能力，同时观察它们在不同子分类问题下性能区别。

第二部分对我们提出的多分类器分层识别算法进行研究。一方面评估算法的整体性能水平，另一方面透过观察算法的中间结果分析算法中的第一步如何对算法的整体性能带来影响，从而解释此算法设计的合理性。

\subsubsection{面向“没有反讽”和“带有反讽”二分类的模型性能分析}
\label{sssec:exp_irony_det_A_base}

对面向“没有反讽”和“带有反讽”的二分类问题，表~\ref{tab:exp_irony_det_A_single_result}和图~\ref{fig:exp_irony_det_A_single_result_bar}显示各个模型在测试集上的性能。注意表中的正确率、召回率、F1值均是针对类别“带有反讽”的指标，对应比赛SemEval2018任务三子任务一关注的主要指标。

对于F1值，2层BiLSTM的表现最好，其次是LSTM配合注意力机制，其F1值和前者非常接近（偏差0.0009），第三为单层的BiLSTM，其F1值和前两者则差距明显（0.0093以上）。对于准确率，单层BiLSTM配合注意力机制和2层BiLSTM配合注意力机制达到最好的数值0.6888 ，第三为LSTM配合注意力机制，其准确率和前两者偏差较小（0.026）。对于正确率，2层BiLSTM配合注意力机制达到最好的数值0.5870 ，其次是单层BiLSTM配合注意力机制，与前者偏差较小（0.0009），第三的LSTM配合注意力机制则和和前两者则差距明显（0.093）。对于召回率，单层的LSTM达到最好的0.8617 ，第二的2层BiLSTM和前者的差距明显（0.0385）。

对于单层BiLSTM和2层BiLSTM，添加注意力机制都使得准确率和“带有反讽”的正确率有所提升，但同时“带有反讽”的召回率明显下降，导致“带有反讽”的F1值也连带下降，可见BiLSTM和2层BiLSTM画添加注意力机制后整个模型的拟合能力是有上升的，但更倾向于预测样本为“没有反讽”，导致“带有反讽”的召回率下降，相对地更少比例的样本被误判为“带有反讽”，因而正确率稍为提高。另外CNN在添加注意力机制后，除召回率以外的三项指标都达到了各个模型中最差的性能，可见虽然在公式上注意力机制可以配合CNN使用，但实际性能并不理想。

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{\linewidth}
  \caption{面向“没有反讽”和“带有反讽”二分类的模型性能}
  \label{tab:exp_irony_det_A_single_result}
    \begin{tabularx}{\linewidth}{X|llll}
    \toprule[1.5pt]
    & 准确率 & 正确率 & 召回率 & F1值 \\
    \hline
    CNN & 0.6658 (6) & 0.5548 (6) & 0.7974 (5) & 0.6544 (5) \\ % A_cnn_ek_1553221371
    CNN+注意力机制 & 0.6008 (12) & 0.4980 (12) & 0.8039 (3) & 0.6150 (12) \\  % A_cnn_ek_1554345958
    \hline
    GRU & 0.6607 (7) & 0.5542 (7) & 0.7395 (9) & 0.6336 (10) \\ % A_gru_ek_1553070254
    GRU+注意力机制 & 0.6569 (10) & 0.5482 (9) & 0.7685 (7) & 0.6399 (9) \\ % A_gru_ek_1553074900
    \hline
    BiGRU & 0.6594 (8) & 0.5534 (8) & 0.7331 (10) & 0.6307 (11) \\ % A_bgru_ek_1553075855
    BiGRU+注意力机制 & 0.6582 (9) & 0.5473 (10) & 0.8006 (4) & 0.6501 (7) \\ % A_bgru_ek_1553068355
    \hline
    LSTM & 0.6390 (11) & 0.5276 (11) & \bf 0.8617 (1) & 0.6545 (4) \\ % A_lstm_ek_1553071939
    LSTM+注意力机制 & 0.6862 (3) & 0.5768 (3) & 0.7846 (6) & 0.6640 (2) \\ % A_lstm_ek_1553075765
    \hline
    BiLSTM & 0.6798 (4) & 0.5721 (4) & 0.7653 (8) & 0.6547 (3) \\ % A_blstm_ek_1553075473
    BiLSTM+注意力机制 & \bf 0.6888 (1) & 0.5861 (2) & 0.7331 (10) & 0.6514 (6) \\ % A_blstm_ek_1553583756
    \hline
    2层BiLSTM & 0.6709 (5) & 0.5577 (5) & 0.8232 (2) & \bf 0.6649 (1) \\ % A_nblstm_ek_1554346535
    2层BiLSTM+注意力机制 & \bf 0.6888 (1) & \bf 0.5870 (1) & 0.7267 (12) & 0.6494 (8) \\ % A_nblstm_ek_1554346515
    \bottomrule[1.5pt]
    \end{tabularx}
  \end{minipage}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{img/exp_irony_det_A_single_result_bar.png}
  \caption{面向“没有反讽”和“带有反讽”二分类的模型性能}
  \label{fig:exp_irony_det_A_single_result_bar}
\end{figure}

\subsubsection{面向反讽四分类的模型性能分析}
\label{sssec:exp_irony_det_B_base}

对于面向反讽四分类问题，表~\ref{tab:exp_irony_det_B_result}和图~\ref{fig:exp_irony_det_B_single_result_bar}显示各个模型在测试集上的性能。注意表中的正确率、召回率、F1值均是
各类别对应指标数据的宏平均，对应比赛SemEval2018任务三子任务二关注的主要指标。

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{\linewidth}
  \caption{面向反讽四分类的模型性能}
  \label{tab:exp_irony_det_B_result}
    \begin{tabularx}{\linewidth}{X|llll}
    \toprule[1.5pt]
    & 准确率 & 正确率 & 召回率 & F1值 \\
    \hline
    CNN & 0.6531 (4) & \bf 0.5090 (1) & 0.4667 (5) & 0.4432 (7) \\ % B_cnn_ek_1554446864
    CNN+注意力机制 & 0.6186 (10) & 0.4467 (7) & 0.4214 (12) & 0.4030 (12) \\ % B_cnn_ek_1554446879
    \hline
    GRU & 0.6148 (12) & 0.4437 (8) & 0.4693 (4) & 0.4476 (5) \\ % B_gru_ek_1554447274
    GRU+注意力机制 & 0.6531 (4) & 0.4253 (10) & 0.4605 (7) & 0.4370 (8) \\ % B_gru_ek_1554447525
    \hline
    BiGRU & \bf 0.6722 (1) & 0.4868 (4) & 0.4779 (2) & \bf 0.4768 (1) \\ % B_bgru_ek_1554447516
    BiGRU+注意力机制 & 0.6301 (9) & 0.4543 (6) & 0.4638 (6) & 0.4497 (4) \\ % B_bgru_ek_1554447697
    \hline
    LSTM & 0.6186 (10) & 0.4313 (9) & 0.4490 (9) & 0.4307 (9) \\ % B_lstm_ek_1554447721
    LSTM+注意力机制 & 0.6416 (6) & 0.4046 (12) & 0.4394 (10) & 0.4148 (11) \\ % B_lstm_ek_1554447878
    \hline
    BiLSTM & 0.6582 (2) & 0.4875 (3) & 0.4537 (8) & 0.4447 (6) \\ % B_blstm_ek_1554447955
    BiLSTM+注意力机制 & 0.6352 (7) & 0.4168 (11) & 0.4386 (11) & 0.4160 (10) \\ % B_blstm_ek_1554448216
    \hline
    2层BiLSTM & 0.6582 (2) & 0.5068 (2) & 0.4762 (3) & 0.4644 (3) \\ % B_nblstm_ek_1554448237
    2层BiLSTM+注意力机制 & 0.6314 (8) & 0.4824 (5) & \bf 0.4864 (1) & 0.4657 (2) \\ % B_nblstm_ek_1554448594
    \bottomrule[1.5pt]
    \end{tabularx}
  \end{minipage}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{img/exp_irony_det_B_single_result_bar.png}
  \caption{面向反讽四分类的模型性能}
  \label{fig:exp_irony_det_B_single_result_bar}
\end{figure}

对于F1值，BiGRU达到最好的数值（0.4768），其次是2层BiLSTM以及2层BiLSTM配合注意力机制，与前者的数值差距明显（约0.0111）。对于准确率，同样由BiGRU达到最好的数值（0.6722），其次是BiLSTM和2层BiLSTM，和前者的数值差距明显（0.014以上）。对于正确率，CNN和2层BiLSTM的性能较好（在0.5以上），第三的BiLSTM则在0.49以下。对于召回率，2层BiLSTM配合注意力机制达到最好的0.4864 ，其次的BiGRU和BiLSTM则和前者差距明显（0.0085）。

另外，六组模型在添加注意力机制后正确率、召回率和F1值都有所下降（仅2层BiLSTM的召回率例外），而对于准确率较高的BiGRU、BiLSTM和CNN在添加注意力机制后准确率同样有所下降，可以认为添加注意力机制在此子分类问题中并不没有带来性能提升。


\subsubsection{面向“没有反讽”和“基于相反语义的反讽”二分类的模型性能分析}
\label{sssec:exp_irony_det_Bb01_base}

对于面向“没有反讽”和“基于相反语义的反讽”的二分类问题，表~\ref{tab:exp_irony_det_Bb01_result}和图~\ref{fig:exp_irony_det_Bb01_single_result_bar}显示各个模型在测试集上能达到的性能。注意表中的正确率、召回率、F1值指“没有反讽”和“基于相反语义的反讽”两个类别对应指标的宏平均。

对于F1值，LSTM配合注意力机制达到最大数值的0.7752 ，其后依次为BiGRU和GRU，和前者差距约较小（约0.0047)。对于准确率，同样是LSTM配合注意力机制达到最好的效果（0.8275），其后依次为GRU和BiGRU，和前者差距大（0.0157）。对于正确率，还是 LSTM配合注意力机制的数值最高（0.7717），其后依次为GRU和BiGRU，和前者差距较大（0.0151）。对于召回率，数值最高的是BiGRU（0.7993），其次是GRU和LSTM，和前者差距均较小（约0.0049）。

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{\linewidth}
  \caption{面向“没有反讽”和“基于相反语义的反讽”的二分类各模型性能}
  \label{tab:exp_irony_det_Bb01_result}
    \begin{tabularx}{\linewidth}{X|llll}
    \toprule[1.5pt]
    & 准确率 & 正确率 & 召回率 & F1值 \\
    \hline
    CNN & 0.7991 (5) & 0.7438 (5) & 0.7791 (7) & 0.7562 (5) \\ % Bb01_cnn_ek_1554448736
    CNN+注意力机制 & 0.6829 (12) & 0.6494 (12) & 0.6909 (12) & 0.6470 (12) \\ % Bb01_cnn_ek_1554448788
    \hline
    GRU & 0.8100 (2) & 0.7566 (2) & 0.7944 (2) & 0.7699 (3) \\ % Bb01_gru_ek_1554448924
    GRU+注意力机制 & 0.7677 (9) & 0.7196 (9) & 0.7679 (10) & 0.7303 (9) \\ % Bb01_gru_ek_1554449053
    \hline
    BiGRU & 0.8085 (3) & 0.7565 (3) & \bf 0.7993 (1) & 0.7705 (2) \\ % Bb01_bgru_ek_1554449115
    BiGRU+注意力机制 & 0.7755 (8) & 0.7301 (8) & 0.7831 (5) & 0.7412 (8) \\ % Bb01_bgru_ek_1555407125
    \hline
    LSTM & 0.8053 (4) & 0.7525 (4) & 0.7932 (3) & 0.7661 (4) \\ % Bb01_lstm_ek_1554449707
    LSTM+注意力机制 & \bf 0.8257 (1) & \bf 0.7717 (1) & 0.7791 (7) & \bf 0.7752 (1) \\ % Bb01_lstm_ek_1554449864
    \hline
    BiLSTM & 0.7551 (10) & 0.7169 (10) & 0.7734 (9) & 0.7236 (10) \\ % Bb01_blstm_ek_1554449881
    BiLSTM+注意力机制 & 0.7174 (11) & 0.6909 (11) & 0.7460 (11) & 0.6889 (11) \\ % Bb01_blstm_ek_1554450198
    \hline
    2层BiLSTM & 0.7849 (7) & 0.7339 (7) & 0.7795 (6) & 0.7465 (7) \\ % Bb01_nblstm_ek_1554450231
    2层BiLSTM+注意力机制 & 0.7928 (6) & 0.7421 (6) & 0.7888 (4) & 0.7554 (6) \\ % Bb01_nblstm_ek_1554450448
    \bottomrule[1.5pt]
    \end{tabularx}
  \end{minipage}
\end{table}

总的来说，LSTM配合注意力机制在四项指标中的三项都达到了最好的性能。GRU和BiGRU的性能非常接近，各项指标在所有模型中排第二和第三。从数学模型上看，BiGRU比单层GRU多一个把文本反向输入的GRU通道，提高了召回率的同时稍微降低了准确率和正确率，显示反向输入的GRU通道能额外捕足到“基于相反语义的反讽”的相关特征。但相对地BiLSTM在四项指标上都明显低于LSTM，原因可能有两点，一是LSTM本身对“基于相反语义的反讽”的建模能力较差，二是BiLSTM的模型参数过多导致对训练集的过拟合。

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{img/exp_irony_det_Bb01_single_result_bar.png}
  \caption{面向“没有反讽”和“基于相反语义的反讽”的二分类各模型性能}
  \label{fig:exp_irony_det_Bb01_single_result_bar}
\end{figure}

\subsubsection{面向“没有反讽”和“情景反讽”二分类的模型性能分析}
\label{sssec:exp_irony_det_Bb02_base}

对于面向“没有反讽”和“情景反讽”的二分类问题，表~\ref{tab:exp_irony_det_Bb02_result}和图~\ref{fig:exp_irony_det_Bb02_single_result_bar}显示各个模型在测试集上的性能。注意表中的正确率、召回率、F1值指“没有反讽”和“情景反讽”两个类别对应指标的宏平均。

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{\linewidth}
  \caption{面向“没有反讽”和“情景反讽”的二分类模型性能}
  \label{tab:exp_irony_det_Bb02_result}
    \begin{tabularx}{\linewidth}{X|llll}
    \toprule[1.5pt]
    & 准确率 & 正确率 & 召回率 & F1值 \\
    \hline
    CNN & \bf 0.8656 (1) & \bf 0.7634 (1) & 0.6167 (7) & 0.6473 (7) \\ % Bb02_cnn_ek_1554450719
    CNN+注意力机制 & 0.8477 (5) & 0.6865 (5) & 0.5917 (11) & 0.6117 (11) \\ % Bb02_cnn_ek_1554450772
    \hline
    GRU & 0.8495 (4) & 0.6942 (4) & 0.6024 (10) & 0.6242 (10) \\ % Bb02_gru_ek_1554450862
    GRU+注意力机制 & 0.8333 (11) & 0.6708 (8) & 0.6556 (4) & 0.6625 (4) \\ % Bb02_gru_ek_1554451013
    \hline
    BiGRU & 0.8423 (6) & 0.6645 (11) & 0.5789 (12) & 0.5951 (12) \\ % Bb02_bgru_ek_1554451047
    BiGRU+注意力机制 & 0.8423 (6) & 0.6825 (6) & 0.6416 (5) & 0.6572 (6) \\ % Bb02_bgru_ek_1554451155
    \hline
    LSTM & 0.8513 (2) & 0.7027 (3) & 0.6372 (6) & 0.6590 (5) \\ % Bb02_lstm_ek_1554451286
    LSTM+注意力机制 & 0.8387 (8) & 0.6676 (10) & 0.6153 (8) & 0.6325 (8) \\ % Bb02_lstm_ek_1554451194
    \hline
    BiLSTM & 0.8351 (10) & 0.6575 (12) & 0.6084 (9) & 0.6243 (9) \\ % Bb02_blstm_ek_1554451336
    BiLSTM+注意力机制 & 0.8369 (9) & 0.6797 (7) & 0.6674 (3) & 0.6731 (3) \\ % Bb02_blstm_ek_1554451401
    \hline
    2层BiLSTM & 0.8262 (12) & 0.6691 (9) & 0.6803 (2) & 0.6743 (2) \\ % Bb02_nblstm_ek_1554451496
    2层BiLSTM+注意力机制 & 0.8513 (2) & 0.7076 (2) & \bf 0.6806 (1) & \bf 0.6924 (1) \\ % Bb02_nblstm_ek_1554451575
    \bottomrule[1.5pt]
    \end{tabularx}
  \end{minipage}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{img/exp_irony_det_Bb02_single_result_bar.png}
  \caption{面向“没有反讽”和“情景反讽”的二分类模型性能}
  \label{fig:exp_irony_det_Bb02_single_result_bar}
\end{figure}

对于F1值和召回率，2层BiLSTM配合注意力机制在这两个指标上都达到了最好的效果（数值分别为0.6924 和 0.6806），其次是2层BiLSTM，第三是单层的BiLSTM配合注意力机制，但后两者在准确率和正确率这两项指标上都排在靠后的位置。而对于准确率和正确率，均由CNN达到最好的效果（数值分别为0.8656和 0.7634），其次是2层BiLSTM配合注意力机制，第三是单层的LSTM。

整体上，2层BiLSTM配合注意力机制在四项指标上的都达到了靠前的效果，显示2层BiLSTM配合注意力机制对区分“没有反讽”和“情景反讽”有明显较好的建模能力。另外CNN虽然在准确率和正确率上都达到最好的性能，但由于召回率数值太低导致了F1值明显低于第一的F1值（差距约0.045），显示CNN只对部分“情景反讽”的模式有较好的建模能力，所以识别为“情景反讽”的样本基本正确，但召回的样本不多。

\subsubsection{面向“没有反讽”和“其他反讽”二分类的模型性能分析}
\label{sssec:exp_irony_det_Bb03_base}

对于面向“没有反讽”和“其他反讽”的二分类问题，表~\ref{tab:exp_irony_det_Bb03_result}和图~\ref{fig:exp_irony_det_Bb03_single_result_bar}显示各个模型在测试集上的性能。注意表中的正确率、召回率、F1值指“没有反讽”和“其他反讽”两个类别对应指标的宏平均。

对于F1值，性能最好的是CNN（0.6016），其次是GRU，与前者差距明显（约0.0163），第三为BiLSTM，明显低于CNN的数值（差距约为0.0489）。对于准确率，同样是CNN达到最高的数值（0.8860），其次是GRU配合注意力机制以及LSTM配合注意力机制，在数值上比较接近（差距仅0.0019）。对于正确率，依然是CNN的性能最优（0.7123），第二是GRU配合注意力机制，但和前者差距较明显（约0.0195），第三的GRU则远差于前两者（差距达0.1以上)。 对于召回率，则是GRU的效果最好（0.5836），其次是CNN，与前者差距较小（约0.0055），第三的BiLSTM则和前两者差距较大（达0.0313）。

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{\linewidth}
  \caption{面向“没有反讽”和“其他反讽”的二分类模型性能}
  \label{tab:exp_irony_det_Bb03_result}
    \begin{tabularx}{\linewidth}{X|llll}
    \toprule[1.5pt]
    & 准确率 & 正确率 & 召回率 & F1值 \\
    \hline
    CNN & \bf 0.8860 (1) & \bf 0.7123 (1) & 0.5781 (2) & \bf 0.6016 (1) \\ % Bb03_cnn_ek_1553500286
    CNN+注意力机制 & 0.7981 (11) & 0.4930 (8) & 0.4934 (11) & 0.4932 (7) \\ % Bb03_cnn_ek_1554453416
    \hline
    GRU & 0.8336 (10) & 0.5873 (3) & \bf 0.5836 (1) & 0.5853 (2) \\ % Bb03_gru_ek_1554452318
    GRU+注意力机制 & 0.8841 (2) & 0.6928 (2) & 0.5070 (7) & 0.4848 (8) \\ % Bb03_gru_ek_1554452300
    \hline
    BiGRU & 0.8411 (8) & 0.5481 (7) & 0.5317 (6) & 0.5353 (6) \\ % Bb03_bgru_ek_1554452373
    BiGRU+注意力机制 & 0.8822 (4) & 0.4419 (11) & 0.4989 (9) & 0.4687 (10) \\ % Bb03_bgru_ek_1554452659
    \hline
    LSTM & 0.8486 (6) & 0.5603 (5) & 0.5360 (4) & 0.5409 (4) \\ % Bb03_lstm_ek_1554452412
    LSTM+注意力机制 & 0.8841 (2) & 0.4421 (10) & 0.5000 (8) & 0.4692 (9) \\ % Bb03_lstm_ek_1554452800
    \hline
    BiLSTM & 0.8430 (7) & 0.5663 (4) & 0.5468 (3) & 0.5527 (3) \\ % Bb03_blstm_ek_1554452497
    BiLSTM+注意力机制 & 0.8822 (4) & 0.4419 (11) & 0.4989 (9) & 0.4687 (10) \\ % Bb03_blstm_ek_1554452804
    \hline
    2层BiLSTM & 0.8355 (9) & 0.5483 (6) & 0.5356 (5) & 0.5393 (5) \\ % Bb03_nblstm_ek_1554452506
    2层BiLSTM+注意力机制 & 0.7944 (12) & 0.4571 (9) & 0.4633 (12) & 0.4600 (12) \\ % Bb03_nblstm_ek_1554452977
    \bottomrule[1.5pt]
    \end{tabularx}
  \end{minipage}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{img/exp_irony_det_Bb03_single_result_bar.png}
  \caption{面向“没有反讽”和“其他反讽”的二分类模型性能}
  \label{fig:exp_irony_det_Bb03_single_result_bar}
\end{figure}

整体上，CNN在三项指标上都达到了最好的效果，而在召回率也逼近最好的GRU，显示CNN对“其他反讽”有明显较好的建模能力。对比面向“没有反讽”和“情景反讽”的二分类实验，CNN在准确率和正确率上同样达到最好的效果，但召回率和F1值都排在靠后的位置，可见相对于“情景反讽”，CNN对“其他反讽”的建模能力更好。 

\subsubsection{面向“没有反讽”和“带有反讽”二分类的系统性能分析}

经过前面各章节的分析，我们已经对各个子分类问题中不同模型的性能有大致了解，接下来将研究由多组子分类器集成得出的反讽识别系统的性能，并和比赛SemEval-2018任务三的参赛系统比较来评估我们系统的性能水平。

首先对于SemEval-2018任务三的子任务一，即面向“没有反讽”和“带有反讽”的二分类问题，基于章节~\ref{sssec:exp_irony_det_A_base}的实验结果，我们最终选择以F1值最高的2层BiLSTM作为子分类器的模型，按照章节~\ref{ssec:exp_irony_det_model_training}训练出9个分类器组成分类器组，按照章节~\ref{sec:exp_irony_det_framework}，由该分类器组进行多数投票来判断一条微博是否带有反讽。

表~\ref{tab:exp_irony_det_A_other_comp}显示我们的系统和SemEval-2018任务三子任务一中其他参赛系统在测试集上的性能。注意表中的正确率、召回率、F1值均是针对类别“带有反讽”的指标。在SemEval-2018任务三子任务一的最终测试阶段，参赛系统共43个，表中仅显示排名前10（按照F1值排名）或在某项指标排名靠前的参赛系统，其中队伍名称为THU\_HCSI对应我们当时提交的系统，排名第8。

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{\linewidth}
  \caption{SemEval-2018任务三子任务一参赛系统性能} % 共43个参赛系统
  \label{tab:exp_irony_det_A_other_comp}
    \begin{tabularx}{\linewidth}{c|X|llll}
    \toprule[1.5pt]
    排名 & 队伍名称 & 准确率 & 正确率 & 召回率 & F1值 \\
    \hline 
    1 & THU\_NGN & \bf 0.7347 (1) & 0.6304 (4) & 0.8006 (4) & \bf 0.7054 \\
    2 & NTUA-SLP & 0.7321 (2) & 0.6535 (2) & 0.6913 (13) & 0.6719 \\
    3 & WLV & 0.6429 (15) & 0.5317 (20) & 0.8360 (2) & 0.6500 \\
    4 & (无) & 0.6607 (10) & 0.5506 (13) & 0.7878 (7) & 0.6481 \\
    5 & NIHRIO, NCL & 0.7015 (3) & 0.6091 (5) & 0.6913 (13) & 0.6476 \\
    6 & DLUTNLP-1 & 0.6276 (19) & 0.5199 (23) & 0.7974 (5) & 0.6294 \\
    7 & ELiRF-UPV & 0.6110 (23) & 0.5059 (27) & 0.8328 (3) & 0.6294 \\
    8 & \bf THU\_HCSI & 0.6594 (11) & 0.5550 (11) & 0.7138 (10) & 0.6245 \\
    9 & CJ & 0.6671 (8) & 0.5654 (9) & 0.6945 (12) & 0.6234 \\ 
    10 & \#NonDicevoSulSerio & 0.6786 (7) & 0.5831 (8) & 0.6656 (15) & 0.6216 \\
    \hline
    15 & (无) & 0.5651 (31) & 0.4731 (33) & \bf 0.8489 (1) & 0.6076 \\
    \hline
    43 & INGEOTEC-IIMAS & 0.6276 (19) & \bf 0.8800 (1) & 0.0707 (37) & 0.1310 \\
    \hline 
    & 单个分类器 & 0.6709 (8) & 0.5577 (10) & 0.8232 (4) & 0.6649 (3) \\ % A_nblstm_ek_1554346535
    & 我们的系统 & 0.7258 (3) & 0.6176 (5) & 0.8103 (4) & 0.7010 (2) \\
    \bottomrule[1.5pt]
    \end{tabularx}
  \end{minipage}
\end{table}

首先观察各项指标上我们系统的性能水平。对于F1值，系统的数值为0.7010，对应当时排名第二，略低于第一名的0.7050，而显着高于当时第二名的0.6719（差距约0.03）。对于准确率，系统的数值为0.7256，对应当时排名第三，和第一名的差距约为0.009。对于正确率，系统的数值为0.6176，对应当时排名第五。对于召回率，系统的数值为0.8103，对应当时排名第四。总的来说系统在上述四项指标上都达到了当时排名靠前的性能，对比我们当时提交的系统有了明显的提升。

另外对比单个子分类器（即单个2层BiLSTM模型的分类器）和整个系统的识别性能，系统在准确率、正确率和F1值上都有明显的提升，而召回率有轻微的下降，显示采用多数投票方法有效基于多个子分类器达到更好的识别性能。

\subsubsection{面向反讽四分类的系统性能分析}

接下来分析面向反讽四分类问题所提出的多分类器分层识别算法的性能，对应SemEval-2018任务三的子任务二。按照章节~\ref{sec:exp_irony_det_framework}，反讽四分类算法由四个子分类问题对应的分类器组所组成。对于和原问题相同的反讽四分类，根据章节~\ref{sssec:exp_irony_det_B_base}的实验结果，采用BiGRU作为第一组分类器的模型。对于面向“没有反讽”和“基于相反语义的反讽”的二分类问题，按照章节~\ref{sssec:exp_irony_det_Bb01_base}的实验结果，采用LSTM配合注意力机制作为第二组分类器的模型。对于“没有反讽”和“情景反讽”的二分类问题，按照章节~\ref{sssec:exp_irony_det_Bb02_base}的实验结果，采用2层BiLSTM+注意力机制作为第三组分类器的模型。对于“没有反讽”和“其他反讽”的二分类问题，按照章节~\ref{sssec:exp_irony_det_Bb03_base}的实验结果，采用CNN作为第四组分类器的模型。按照章节~\ref{ssec:exp_irony_det_model_training}，基于选定的模型分别为每个分类器组训练5个分类器。

最后按照章节~\ref{sec:exp_irony_det_framework}中给出的识别流程，透过逐步结合各组分类器的投票结果得出微博的反讽类别。对于算法中第二、三、四组分类器的参数$thr_2$、$thr_3$和$thr_4$ 均设置为3，即对于每个子分类问题，直接按照多数投票的结果调整预测标签。

表~\ref{tab:exp_irony_det_B_other_comp}显示我们的系统和SemEval-2018任务三子任务二中其他参赛系统在测试集上的性能。注意表中的正确率、召回率、F1值都是针对各类别对应指标的宏平均。在SemEval-2018任务三子任务二的最终测试阶段，参赛系统共31个，表中仅显示排名前10（按照F1值排名）的参赛系统，而我们当时并未参与子任务二。
 
首先观察各项指标上我们系统的性能水平。对于F1值，系统的数值为0.5205，对应当时排名第一，显着高于当时第一名的0.5074。对于准确率，系统的数值为0.6939，对应当时准确率排名第二，明显低于最高数值的0.7321。对于正确率，系统的数值为0.6003，对应当时正确率排名第一，显着高于当时最高0.5768的正确率。
对于召回率，系统的数值为0.5241，对应当时召回率排名第二，明显低于最高数值的0.5414。

总的来说，我们的系统在各项指标上都达到了靠前的水平，而且在主要评价指标F1值上显着超过了当时的第一名。对比排名第一的系统，系统的准确率较低，而正确率和召回率都比它高，可以推断系统成功召回了较多“带有反讽”的细分类别的样本，但同时把较多真实标签为“没有反讽”的样本误判为“带有反讽”的细分类别。对于准确率较低但宏平均F1值较高这一点，在数据不均匀的多分类问题中是个常见的情况。因为当系统对样本量较少的类别有较好的识别能力时，对样本量较多的类别的识别能力会相对较差，导致整体准确率下降。在数据不均匀的情况下各项性能指标一般不可兼得，因此在具体应用场景下需要慎重选择评价指标，并作针对性的算法设计。

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{\linewidth}
  \caption{SemEval-2018任务三子任务二参赛系统性能} % 共31个参赛系统
  \label{tab:exp_irony_det_B_other_comp}
    \begin{tabularx}{\linewidth}{c|X|llll}
    \toprule[1.5pt]
    排名 & 队伍名称 & 准确率 & 正确率 & 召回率 & F1值 \\
    \hline 
    1 & (无) & \bf 0.7321 (1) & \bf 0.5768 (1) & 0.5044 (4) & 0.5074 \\
    2 & NTUA-SLP & 0.6518 (4) & 0.4959 (4) & 0.5124 (2) & 0.4959 \\
    3 & \bf THU\_NGN & 0.6046 (9) & 0.4860 (6) & \bf 0.5414 (1) & 0.4947 \\
    4 & (无) & 0.6033 (10) & 0.4660 (7) & 0.5058 (3) & 0.4743 \\
    5 & NIHRIO, NCL & 0.6594 (3) & 0.5446 (2) & 0.4475 (5) & 0.4437 \\
    6 & Random Decision Syntax Trees & 0.6327 (6) & 0.4868 (5) & 0.4388 (8) & 0.4352 \\
    7 & ELiRF-UPV & 0.6327 (6) & 0.4123 (12) & 0.4404 (7) & 0.4211 \\
    8 & WLV & 0.6709 (2) & 0.4311 (10) & 0.4149 (9) & 0.4153 \\
    9 & \#NonDicevoSulSerio & 0.5446 (18) & 0.4087 (15) & 0.4410 (6) & 0.4131 \\
    10 & INGEOTEC-IIMAS & 0.6441 (5) & 0.5017 (3) & 0.3850 (15) & 0.4055 \\
    \hline
    & 我们的系统 & 0.6939 (2) & \bf 0.6003 (1) & 0.5241 (2) & \bf 0.5205 (1) \\
    \bottomrule[1.5pt]
    \end{tabularx}
  \end{minipage}
\end{table}

另外，由于算法中每一步的输出都可以作为一组预测结果，因此我们观察了算法的中间结果在测试集上的性能。表~\ref{tab:exp_irony_det_B_ensemble_result}显示了算法的中间结果在测试集上的各项指标，注意表中的正确率、召回率、F1值均是针对各类别对应指标的宏平均。

表中第一行的“中间结果I”对应直接由第一组四分类器进行多数投票的识别结果，第二行“中间结果II”是基于第二组分类器的投票对原本被识别为“没有反讽”和“基于相反语义的反讽”的样本重新进行二分类的识别结果，可见各项指标都有所提升。再对比中间结果I和中间结果II的混淆矩阵（分别对应表~\ref{tab:exp_irony_det_B_conf_mat_1}和表~\ref{tab:exp_irony_det_B_conf_mat_2}）可以发现正确召回了9个“没有反讽”的样本，同时误判了3个原本识别正确的“基于相反语义的反讽”的样本，故整体准确率还是有所上升。

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{0.8\linewidth}
  \caption{四分类反讽识别系统最终识别结果和中间结果的性能}
  \label{tab:exp_irony_det_B_ensemble_result}
    \begin{tabularx}{\linewidth}{X|cccc}
    \toprule[1.5pt]
    & 准确率 & 正确率 & 召回率 & F1值 \\
    \hline
    中间结果I & 0.6837 & 0.5606 & 0.4891 & 0.4913 \\
    中间结果II & 0.6913 & 0.5655 & 0.4893 & 0.4949 \\
    中间结果III & 0.6913 & 0.5587 & 0.5231 & 0.5179 \\
    \hline
    最终结果 & \bf 0.6939 & \bf 0.6003 & \bf 0.5241 & \bf 0.5205 \\
    \bottomrule[1.5pt]
    \end{tabularx}
  \end{minipage}
\end{table}

表中第三行的“中间结果III”是基于第三组分类器的投票对原本被识别为“没有反讽”和“情景反讽”的样本重新进行二分类的识别结果，对比“中间结果II”的准确率不变，正确率稍微下降，同时召回率有了明显提高，导致F1值也明显提高。再对比中间结果II和中间结果III的混淆矩阵（分别对应表~\ref{tab:exp_irony_det_B_conf_mat_2}和表~\ref{tab:exp_irony_det_B_conf_mat_3}）可以发现误判了14个原本识别正确的“没有反讽”的样本，同时正确召回了14个“情景反讽”的样本，所以准确率不变，但由于“情景反讽”的样本量较少而“没有反讽”的样本量较多，“情景反讽”的召回率显着上升拉高了宏平均的召回率。这也显示了对于宏平均的指标，关注样本量少的类别能在数值上带来明显提升。

\begin{table}[]
  \centering
  \begin{minipage}[t]{0.8\linewidth}
  \caption{
    \label{tab:exp_irony_det_B_conf_mat_1}
    反讽四分类测试集上中间结果I对应的混淆矩阵
  }
  \begin{tabularx}{\linewidth}{c|c|cccc}
  \toprule[1.5pt]
  \multicolumn{2}{c|}{\multirow{2}{*}} & \multicolumn{4}{c}{预测标签}    \\
  \cline{3-6} 
  \multicolumn{2}{c|}{}
    & 没有反讽 & 反义反讽 & 情景反讽 & 其他反讽  \\
  \hline
  \multirow{4}{*}{真实标签}
    & 没有反讽 & 380 & 73 & 13 & 7 \\
    & 反义反讽 & 36 & 125 & 3 & 0 \\
    & 情景反讽 & 44 & 13 & 25 & 3 \\
    & 其他反讽 & 41 & 10 & 5 & 6 \\
  \bottomrule[1.5pt]
  \end{tabularx}
  \end{minipage}
\end{table}


表中最底一行的“最终结果”是基于第四组分类器的投票对原本被识别为“没有反讽”和“其他反讽”的样本重新进行二分类的识别结果，可见各项指标都有所提高。再对比中间结果III和最终结果的混淆矩阵（分别对应表~\ref{tab:exp_irony_det_B_conf_mat_3}和表~\ref{tab:exp_irony_det_B_conf_mat_4}）可以发现这一步把5个被误判为“其他反讽”的样本改成了“没有反讽”，虽然其中只有2个样本的真实标签为“没有反讽”，但由于被识别为“其他反讽”的样本少，明显提高了“其他反讽”的正确率。

总结以上分析结合，我们的多分类器分层识别算法透过逐步回答子分类问题有效得到更好的识别性能，其中的核心原因有以下两点：

\begin{itemize}

\item 针对子分类问题进行建模。除了第一步决策对应原本的四分类问题，另外三个子分问题只关注其中的两个类别，只针对部分数据进行建模使得对应分类器对特定类别有更好的区分能力。另外从章节~\ref{sssec:exp_irony_det_Bb01_base}、\ref{sssec:exp_irony_det_Bb02_base}、\ref{sssec:exp_irony_det_Bb03_base}可以看出，虽然“基于相反语义的反讽”、“情景反讽”和“其他反讽”都是“带有反讽”的细分类别，但在各个子分类问题上，达到较好识别性能的模型不同，显示这些类别背后的语言特征也不同。因此我们对于不同子分类问题分别选择合适的模型，再透过分层识别的方法结合不同模型的结果，使得系统的整体识别能力比只使用单种模型的效果更好。

\item 针对样本不均匀的情况选择子分类问题。原本的四分类问题可以被拆解成多种子分类问题的叠加，但算法中只考虑了“没有反讽”和各个反讽子类两两组合的二分类问题，原因在于“没有反讽”一类的样本量显着多于其他类别。从中间结果I对应的混淆矩阵（对应表~\ref{tab:exp_irony_det_B_conf_mat_1}）也可以看出这些类别最容易被误判为“没有反讽”，因此针对“没有反讽”和其他类别之间的识别结果进行调整能显着带来性能提升。

\end{itemize}

\begin{table}[]
  \centering
  \begin{minipage}[t]{0.8\linewidth}
  \caption{
    \label{tab:exp_irony_det_B_conf_mat_2}
    反讽四分类测试集上中间结果II对应的混淆矩阵
  }
  \begin{tabularx}{\linewidth}{c|c|cccc}
  \toprule[1.5pt]
  \multicolumn{2}{c|}{\multirow{2}{*}} & \multicolumn{4}{c}{预测标签}    \\
  \cline{3-6} 
  \multicolumn{2}{c|}{}
    & 没有反讽 & 反义反讽 & 情景反讽 & 其他反讽  \\
  \hline
  \multirow{4}{*}{真实标签}
    & 没有反讽 & 389 & 64 & 13 & 7 \\ 
    & 反义反讽 & 39 & 122 & 3 & 0 \\
    & 情景反讽 & 47 & 10 & 25 & 3 \\
    & 其他反讽 & 39 & 12 & 5 & 6 \\
  \bottomrule[1.5pt]
  \end{tabularx}
  \end{minipage}
\end{table}

\begin{table}[]
  \centering
  \begin{minipage}[t]{0.8\linewidth}
  \caption{
    \label{tab:exp_irony_det_B_conf_mat_3}
    反讽四分类测试集上中间结果III对应的混淆矩阵
  }
  \begin{tabularx}{\linewidth}{c|c|cccc}
  \toprule[1.5pt]
  \multicolumn{2}{c|}{\multirow{2}{*}} & \multicolumn{4}{c}{预测标签}    \\
  \cline{3-6} 
  \multicolumn{2}{c|}{}
    & 没有反讽 & 反义反讽 & 情景反讽 & 其他反讽  \\
  \hline
  \multirow{4}{*}{真实标签}
    & 没有反讽 & 375 & 64 & 27 & 7 \\
    & 反义反讽 & 35 & 122 & 7 & 0 \\
    & 情景反讽 & 33 & 10 & 39 & 3 \\
    & 其他反讽 & 38 & 12 & 6 & 6 \\
  \bottomrule[1.5pt]
  \end{tabularx}
  \end{minipage}
\end{table}

\begin{table}[]
  \centering
  \begin{minipage}[t]{0.8\linewidth}
  \caption{
    \label{tab:exp_irony_det_B_conf_mat_4}
    反讽四分类测试集上最终识别结果对应的混淆矩阵
  }
  \begin{tabularx}{\linewidth}{c|c|cccc}
  \toprule[1.5pt]
  \multicolumn{2}{c|}{\multirow{2}{*}} & \multicolumn{4}{c}{预测标签}    \\
  \cline{3-6} 
  \multicolumn{2}{c|}{}
    & 没有反讽 & 反义反讽 & 情景反讽 & 其他反讽  \\
  \hline
  \multirow{4}{*}{真实标签}
    & 没有反讽 & 377 & 64 & 27 & 5 \\
    & 反义反讽 & 35 & 122 & 7 & 0 \\ 
    & 情景反讽 & 36 & 10 & 39 & 0 \\
    & 其他反讽 & 38 & 12 & 6 & 6 \\
  \bottomrule[1.5pt]
  \end{tabularx}
  \end{minipage}
\end{table}

\subsection{错误分析}
\label{ssec:exp_irony_det_error_analysis}

本节将对被系统错误识别的样本进行观察，分析其中的原因，从而对问题有更探入的了解，以及尝试给出下一步的改进方向。以下使用的例子均参照表~\ref{tab:semeval_2018_task3_error}。

\begin{itemize}

\item {\bf 词组语义倾向识别}。参考例子1，其中“blame”表示指责，在字面意思上有明显的负面情感倾向，而“XXX of the Year”意思为年度最佳的某某，整个词组带有正面情感倾向，故和前者对比得出原微博带有“基于相反语义的反讽”。关键在于词组“XXX of the Year”在逐字解读时没有明显的情感倾向，这也是文本情感识别中常见的问题之一。那么要使得基于人工神经网络的算法有能力识别词组的语义倾向，其必要条件之一是在训练集中遇到过类似的词组，对此可以透过收集更多训练样本来保证对常用词组的复盖率，但对于不常用或新出现的词组则只能额外引入语言知识。

\item {\bf 场景描述识别}。参考例子2，用户表示他在担任校医当天发烧了，其中“担任校医”为场景，“发烧”的发生和对“担任校医”的预期相反，因此属于“情景反讽”，但“fever”本身间接带有负面情感，该样本被系统误判成了“基于相反语义的反讽”。同样地对于例子3，用户表示工作怎么能在他没有上班的期间完成，其中“没有上班”为场景，“工作完成”的发生和对“没有上班”的预期相反，因此属于“情景反讽”，但“off week”间接带有正面情感，因而被系统识别为“基于相反语义的反讽”。再观察系统在测试集上的混淆矩阵（表~\ref{tab:exp_irony_det_B_conf_mat_4}），可以发现有相当一部分“情景反讽”的样本被误判为“基于相反语义的反讽”，由此推断其中的原因之一在于部分“情景反讽”的样本中确实
包含带有情感极性的部分，因而导致了混淆，相对地专注于识别“场景”的出现会是召回这部分样本的关键。

\item {\bf 一词多义}。参考例子4，“\#Starbucks”是一家国际连锁咖啡店的名字，而在咖啡店的场景下，“tall”指咖啡杯一种大小，“blonde”为该店某个咖啡系列的名称，而在日常生活场景中，“tall blonde”还有高挑金发女子的意思，即出现一词多义，而后者的意思在咖啡店场景下发生就产生了和预期相反的效果，因此属于“情景反讽”。换言之，要识别出例子中的“情景反讽”就要求系统认识到“tall blonde”具有咖啡以外的意思。因为在分类器模型中，每个单词都以一个固定的词向量表示，因此无法表示一词多义，更无法对多种含意的词组进行建模，在模型中考虑一词多义是解决方法之一。另外，让系统能够将“Starbucks”和咖啡关联起来则要求在训练集上有包含对应信息的样本。

\item {\bf 信息不足}。参考例子5，“clashupdate”并非标准英语单词或网络上的常用单词，后面紧接着一个超链接，仅凭字面意思无法理解用户要表达的意思。而访问该链接对应网页会发现插图为游戏“Clash of Clans”的更新提示，所以文本中的“clashupdate”应对应“clash update”，依然没有表示反讽的意思，但我们发现原微博的完整文本内容为“clashupdate \#not”，其中“\#not”在微博反讽识别的研究中是最常被用于对微博进行自动标注的井号标签之一，被组织者在准备数据集时故意过滤了。在比赛中，尝试找到微博原文有悖于组织者的初衷（不依赖井号标签进行分类），但在具体应用场景中，若要正确判断这些样本就可以考虑引入链接中的评论，这也对应下一章中探讨引入上下文的情感识别。

\end{itemize}

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{\linewidth} % 如果想在表格中使用脚注，minipage是个不错的办法
  \caption{反讽识别子任务二中被系统误判的样本例子}
  \label{tab:semeval_2018_task3_error}
  \begin{tabularx}{\linewidth}{c|l|X}
    \toprule[1.5pt]
    编号 & 类别 & 微博 \\
    \hline
    1 & 反义反讽 & I blame my mom. Mother of the Year \\
    2 & 情景反讽 & So I'm the school nurse today. And I have a fever. \\
    3 & 情景反讽 & Also it is funny how things at work get done when I'm on my off week \\
    4 & 情景反讽 & Just walked in to \#Starbucks and asked for a “tall blonde” Hahahaha \\
    5 & 其他反讽 & clashupdate http://t.co/1bFOsIwnI5 \\
    \bottomrule[1.5pt]
  \end{tabularx}
  \end{minipage}
\end{table}

\section{本章小结}

在本章中我们提出了一种多分类器分层识别算法，并应用于面向微博的反讽识别。我们基于国际比赛SemEval-2018任务三的两个子任务进行了多组实验。对于子任务一，即“没有反讽”和“带有反讽”二分类，我们的系统达到了当时的参赛系统中靠前的性能，和我们当时提交的系统性能相比有了显着的提升。对于子任务二，即“没有反讽”、“基于相反语义的反讽”、“情景反讽”和“其他反讽”四分类问题，我们采用了我们提出的多分类器分层识别算法，实验结果显示算法的识别性能超过了当时参赛系统中的第一名。另外，对算法中间结果的分析验证了算法中每一步的有效性，并解释它如何对算法的整体性能带来影响。最后我们对被系统错误识别的样本进行分析，指出系统的不足之处并给出对应的改进方向。
