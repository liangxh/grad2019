\chapter{面向微博的反讽识别}
\label{cha:exp_irony_det}

\section{本章引论}

社交媒体的发展对我们的语言体系带来了很大的影响，网络上出现了很多新颖的用词和句式，语言的表达方式越来越丰富，也越来越复杂。而反讽是在网络上常见的语言修饰手法之一, 这为反讽相关的研究带来了充足的数据基础。Henry Watson Fowler在《The King's English》一书中指出反讽的使用使得“表面意思和实际意思不同”。譬如一个人说“你这想法真有创意”，在字面意思上是对另一个人的赞同，但在特定背景下，如后接一句“你真相信这能实现吗”，那么发言者实际上可能暗示这个想法无法落地，表面上称赞为“有创意”，其实是指责这种想法不切实际。这在意图识别当中尤其重要，忽略反讽的使用会导致对内容的错误理解，而且这种理解是和真实意思截然相反的，因此识别出反讽的使用或许对相关的场景如情感识别、人机交互能起着正面的作用。

根据Joshi等人\cite{joshi2017automatic}对近年相关研究的总结，反讽识别可以大致分成基于规则的方法和基于机器学习的方法。基于规则的方法透过人工找出反讽中的语言规律，设计出对应的模式，然后在新样本中尝试识别出相应的模式出现。和机器学习方法对比，基于规则的方法优点在于无需模型训练，但要求研究员对反讽有充分的语言理解，设计的模式对样本的复盖程度决定了算法的识别能力。而随着近年深度学习快速发展，一些研究更专注于对词嵌入向量的使用以及人工神经网络的设计和选择。

国际比赛SemEval-2018的任务三\cite{van2018semeval}旨在促进英语微博中的反讽识别研究，其中包含了两个子任务。子任务一是二分类的反讽识别，需要识别微博是否有使用反讽。子任务二是四分类的反讽识别，是子任务一的拓展，除了判断微博是否包含反讽，反讽再细分成三个类别：基于相反语义的反讽 
、情景反讽、其他反讽。本章节中我们将基于SemEval-2018的任务三进行实验，采用比赛组织者提供的训练数据和测试数据，并透过和其他参赛系统进行比较来评估我们提出的框架的性能。

本章的内容安排如下。在章节\ref{sec:exp_irony_det_format}中，我们会基于章节\ref{sec:global_problem_analysis}首先给出当前问题的形式化表示。在章节\ref{sec:exp_irony_det_data}中我们再对具体实验数据进行观察，分析微博文本的特性以及各个反讽类别之间的不同。在章节\ref{sec:exp_irony_det_framework}中，我们会基于章节\ref{sec:global_framework}的框架给出我们对当前问题的系统框架。最后在章节\ref{sec:exp_irony_det_exp}给出实验的细节，以及对实验结果进行分析。

\section{形式化表示}
\label{sec:exp_irony_det_format}

在本章中，我们要研究单条微博的反讽类型识别。给定一个反讽类别集合$C$，对于一个微博集合$T$，对任意一条微博$t \in T$，它属于唯一一种情感类别$c \in C$。又给定一个词集合$W$，微博$t$经过文本预处理后可以表示为一个长度为$L$的词序列 $w = <w_1, w_2, ..., w_L>, w_i \in W, i \in [1, L]$。因为没有引入上下文信息，所以背景$B$在模型中忽略。那么我们的目标是找出一个映射关系$F_C$，使得$c=F_C(w)$。

\section{数据观察}
\label{sec:exp_irony_det_data}

我们的实验完全采用SemEval-2018的任务三比赛组织者提供的数据集，其中的语料收集自微博平台Twitter上发布于2014年至2015年之间的微博，再由人工标注得出每条微博的反讽类型。该比赛的两个子任务均采用了相同的语料但标注稍有不同。子任务一是二分类的反讽识别，需要识别微博是否有使用反讽，各类别的数据分布如表\ref{tab:semeval_2018_task3_A_data}所示，表\ref{tab:semeval_2018_task3_A_sample}为语料中两个类别的例子。可以看出没有反讽和带有反讽两个类别的样本在训练集上大致比例为1:1，在测试集上两个类别的分布大致为3:2。

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{0.7\linewidth} % 如果想在表格中使用脚注，minipage是个不错的办法
  \caption{反讽识别子任务一各类别样本数量分布}
  \label{tab:semeval_2018_task3_A_data}
    \begin{tabularx}{\linewidth}{X|XX}
    \toprule[1.5pt]
    数据集 & 没有反讽 & 带有反讽 \\  
    \hline
    训练集 & 1923 & 1911 \\
    测试集 & 473  & 311 \\
    \bottomrule[1.5pt]
    \end{tabularx}
  \end{minipage}
\end{table}

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{0.8\linewidth} % 如果想在表格中使用脚注，minipage是个不错的办法
  \caption{反讽识别子任务一样例}
  \label{tab:semeval_2018_task3_A_sample}
  \begin{tabularx}{\linewidth}{l|X}
    \toprule[1.5pt]
    反讽类别 & 例子 \\
    \hline
    没有反讽 & Had no sleep and have got school now \#not happy \\
    带有反讽 & I just love when you test my patience!! \#not \\
    \bottomrule[1.5pt]
  \end{tabularx}
  \end{minipage}
\end{table}

子任务二是四分类的反讽识别，是子任务一的拓展，除了判断微博是否包含反讽，反讽再细分成三个类别：基于相反语义的反讽、情景反讽、其他反讽。各类别的数据分布如表\ref{tab:semeval_2018_task3_B_data}所示，表\ref{tab:semeval_2018_task3_B_sample}为语料中各反讽类别的例子。可以看出带有反讽一类细分成三个子反讽类别后各个类别的分别变得明显的不均匀，三个子反讽类别中的样本数据量差异也较大，基于相反语义的言语反讽占了其中一半以上，在模型训练过程应有对应策略处理。

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{\linewidth} % 如果想在表格中使用脚注，minipage是个不错的办法
  \caption{反讽识别子任务二各类别样本数量分布}
  \label{tab:semeval_2018_task3_B_data}
    \begin{tabularx}{\linewidth}{X|XXXX}
    \toprule[1.5pt]
    数据集 & 没有反讽 & 基于相反语义的反讽 & 情景反讽 & 其他反讽\\  
    \hline
    训练集 & 1923 & 1390 & 316  & 205 \\
    测试集 & 473  & 164  & 85  & 62 \\
    \bottomrule[1.5pt]
    \end{tabularx}
  \end{minipage}
\end{table}

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{\linewidth} % 如果想在表格中使用脚注，minipage是个不错的办法
  \caption{反讽识别子任务二样例}
  \label{tab:semeval_2018_task3_B_sample}
  \begin{tabularx}{\linewidth}{l|X}
    \toprule[1.5pt]
    \small 反讽类别 & 例子 \\
    \hline
    \small 没有反讽 & Had no sleep and have got school now \#not happy \\
    \small 基于相反语义的反讽 & \small I really love this year’s summer; weeks and weeks of awful weather \\
    \small 情景反讽 & Most of us didn’t focus in the \#ADHD lecture. \#irony \\
    \small 其他反讽 & @someuser Yeah keeping cricket clean, that's what he wants \#Sarcasm \\
    \bottomrule[1.5pt]
  \end{tabularx}
  \end{minipage}
\end{table}

比赛组织者对四种反讽类别给出了对应的说明。对基于相反语义的反讽一类，文本中存在某部分内容表达了可评估的情感极性，但整条微博实际上表达了相反的情感极性。如表\ref{tab:semeval_2018_task3_B_sample}中的例子，“love”在字面意思上表达了正面的情感，但微博后半中“awful weather”提示实际情况引起了发言者的不适，发言者其实在表达对这个夏天坏天气的不满，这和“love”的正面情感恰恰相反。对于情景反讽一类，文本正描述某个场景，其中发生的事情和某种预期不符。如表\ref{tab:semeval_2018_task3_B_sample}中的例子，描述了一个参与讲座的场景，但“我们（us）”并没有专注于这场讲座，和“参与者应该专注于讲座内容”的预期相反。对于其他反讽一类，文本表达了讽刺的意思，但文本的字面意思和发言者表达的意思之间并不存在情感极性的反差。如表\ref{tab:semeval_2018_task3_B_sample}中的例子，发言者表示某人想要保持蟋蟀干净，字面上并不存在情感极性，但在句子后的井号标签提示了发言者表达了讽刺，认为“保持蟋蟀干净”是一样莫名奇妙的事情。最后是没有反讽一类，对于明显不可能包含反讽的文本，或者在背景信息不足的情况下不能确认其包含反讽的文本均属于这一类。

\subsection{文本长度}

我们首先对数据集的文本经过简单分词后统计各个类别的样本中词数量的分布，以下简称为文本长度。表\ref{fig:semeval2018_task3_train_class_len}和表\ref{fig:semeval2018_task3_test_class_len}分别显示了训练集和测试集上各类别样本的文本长度。综合先见样本的文本长度不超过了50，样本的平均文本长度约为20个词。根据表\ref{fig:semeval2018_task3_train_class_len}我们可以看出“情景反讽”的样本整体的文本长度较其他类别的长，“没有反讽”和“基于相反语义的反讽”在文本长度分布上没有明显区别，“其他反讽”整体的文本长度则略高于前两者。再观察表\ref{fig:semeval2018_task3_test_class_len}，同样地“没有反讽”和“基于相反语义的反讽”在文本长度分布上没有明显区别，“情景反讽”的文本长度略高于前两者，但不如训练集上明显。

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{img/semeval2018_task3_train_class_len.png}
  \caption{反讽识别训练集上各类别文本长度分布}
  \label{fig:semeval2018_task3_train_class_len}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{img/semeval2018_task3_test_class_len.png}
  \caption{反讽识别测试集上各类别文本长度分布}
  \label{fig:semeval2018_task3_test_class_len}
\end{figure}

\subsection{文本特征}
\label{ssec:exp_irony_det_data_text}

另外我们注意到语料中存在微博平台Twitter上特有的文本特征，出现频率较高的模式如下：

\begin{itemize}

\item 用户标签“@someuser”，对应微博上的一个用户，使用场景包括以下两种。一是作为句子中的名词使用，二是添加在句前或句末用于提示该用户的参与，不具有句法作用。

\item 井号标签“\#something”，使用场景大致分为以下两种。一是作为句子中的一部分，如“I \#do \#like \#it”，去除井号后满足正规的英语用法，此处以井号标签代替是对内容的强调。另一种是出现在句末，用于提示微博内容与标签对应内容相关，如句末出现“\#sarcasmtweet”明显表示讽刺。

\item 网站链接，在微博平台上支持附加一个网站链接以便，其中平台对链接进行了统一处理，在语料库中网站链接均形如“http://t.co/***”或“https://t.co/***”。

\item 转发标记“RT”（retweet），当用户转发某条微博并添加个人评论时，平台会自动在个人评论后附加转发的微博原文并以“RT”隔开。

\item 一些在社交媒体平台上常见的、有别于正规英语的用法，如拼写错误、缩略词、全大写字母的单词、表情符等，可以参考章节\ref{sec:text_preprocess}描述的例子。

\end{itemize}


\section{框架设计}
\label{sec:exp_irony_det_framework}

对于任务一，由于是二分类问题，我们的系统只包含一组二分类器，透过一次投票得出最终的预测结果，判断微博文本是否采用了反讽修辞。

对于任务二，我们提出的识别系统包含了四组分类器，分别面向不同的子分类问题，并依次经过四次投票结合各组分类器的预测结果来得出最终的预测结果。第一组分类器由$N_1$个四类分类器组成，对应原问题的四个类别。第二组分类器由$N_2$个二类分类器组成，用于区分“没有反讽”和“基于相反语义的反讽”两类。第三组分类器由$N_3$个二类分类器组成，用于区分“没有反讽”和“情景反讽”两类。第四组分类器由$N_4$个二类分类器组成，用于区分“没有反讽”和“其他反讽”两类。

对于一条待识别的微博，决策过程如下：

\begin{itemize}

\item 首先由第一组分类器内部进行多数投票得出$Label^{1}_{MV}$作为第一轮预测结果$Label_{I}$ 。为方便阅读，以下将对一组样本的第一轮预测结果称为中间结果一。

\item 第二步，由第二组分类器投票进行多数投票得出预测结果$Label^{2}_{MV}$，若超过$thr_{2}$分类器投票投给$Label^{2}_{MV}$且第一轮的预测结果$Label_{I}$为“没有反讽”或“基于相反语义的反讽”，则把预测结果修改为$Label^{2}_{MV}$，否则保持不变，以此得出第二轮的预测结果$Label_{II}$。为方便阅读，以下将对一组样本的第二轮预测结果称为中间结果二。

\item 第三步，由第三组分类器投票进行多数投票得出预测结果$Label^{3}_{MV}$，若超过$thr_{3}$分类器投票投给$Label^{3}_{MV}$且第二轮的预测结果$Label_{II}$为“没有反讽”或“情景反讽”，则把预测结果修改为$Label^{3}_{MV}$，否则保持不变，以此得出第三轮的预测结果$Label_{III}$。为方便阅读，以下将对一组样本的第三轮预测结果称为中间结果III。

\item 最后一步，由第四组分类器投票进行多数投票得出预测结果$Label^{4}_{MV}$，若超过$thr_{4}$分类器投票投给$Label^{4}_{MV}$且第三轮的预测结果$Label_{III}$为“没有反讽”或“其他反讽”，则把预测结果修改为$Label^{4}_{MV}$，否则保持不变，以此得出第四轮的预测结果$Label_{IV}$，同时作为整个系统对该微博的最终反讽识别结果。

\end{itemize}

整个决策过程可以分成两大部分。第一部分是初步完成对微博的四分类反讽识别，作为后续决策的基础，对应上述四步决策中的第一步。第二部分是基于第一部分的初步识别结果进行修正，对应上述四步决策中的后三步，每一步只关注被识别的两个类别的样本，由一组专门的子分类器重新给出识别结果，当新的结果充分可信则修改前一步得到的预测结果。在这里决策的可信度由投票数决定，当多数票由超过$thr$个分类器给出则认为充分可信。

\begin{figure}[H]
  \centering
  \includegraphics[width=0.9\textwidth]{img/irony_det_system.pdf}
  \caption{面向四分类反讽识别的系统框架}
  \label{fig:irony_det_system}
\end{figure}

其中对于每个子分类问题，我们都采用了相同的模型框架，如图\ref{fig:irony_det_cls_framework}所示，每个子分类器的输入都是微博文本经过预处理后得到的词序列$\{w_i\}$，然后每个词替换成对应的词嵌入向量，作为特征编码器的输入。特征编码器的目的是把微博文本对应的词向量序列转换成固定长度的特征向量，作为其反讽属性相关的表示向量，首先由一层或多层卷积神经网络或迭归神经网络组成，由于一维神经网络和迭归神经网络的输出均为和输入序列等同长度的向量序列，故最后需要再经过一层处理，对于迭归神经网络一般研究会取序列的最后一个向量，在理论上它结合了整段内容的信息，而对于迭归神经网络一般会采到最大池化层，分别取各特征位上的最大值，最后一种是采用注意力机制，对两类神经网络的序列输出均可结合成定长的表示向量。得到的表示向量作为后面概率预测器的输入，概率预测器的目的是基于微博定长的表示向量得出该微博属于各个反讽类别的概率分布，此处统一采用单层的全联接层和$Softmax$作为激活函数。最后取概率最高者作为分类器对该条微博预测的反讽类别。

考虑到对于不同反讽类型，其文本特征的提取方式可能有所不同，不同模型在各个子分类问题上的建模能力和识别性能也因此不同，所以对于每个子分类问题，我们会分别比较各组模型和参数的性能，以求在子分类问题上达到尽可能好的效果。

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{img/irony_det_cls_framework.pdf}
  \caption{反讽识别子分类器模型框架}
  \label{fig:irony_det_cls_framework}
\end{figure}

\section{实验与分析}
\label{sec:exp_irony_det_exp}

\subsection{数据预处理}

基于我们在章节\ref{ssec:exp_irony_det_data_text}中对样本文本的观察，我们依次采取了以下数据预处理手法

\begin{itemize}

\item 对于不用的用户标签“@someuser”，我们假设具体的用户名不影响微博内容的反讽类型，故统一替换成“<user>”。

\item 对于井号标签“\#something”，我们将他替换成一个字符串序列“<hashtag>”，“something”，“</hashtag>”，此处“<hashtag>”表示井号标签的开始，“</hashtag>”表示井号标签的结束，原因在于在Twitter平台上，井号标签可能由多个单词组成，如语料中出现的井号标签"\#SoCute"，其内容应
砌解成“so”、“cute”两个单词，而语料中多单词组成的井号标签普遍以单词首字母大写示意，故可以简单完成分词，同时在前后添加“<hashtag>”和“</hashtag>”示意中间的内容属于同一个井号标签。

\item 全字母大写的内容在前后添加“<allcap>”和“</allcap>”，示意这一段文本可能是用户故意表示强调的内容。

\item 重复大于等次三次的标点符号以“<repeated>”示意，如“!!!”替换成序列“!”和“<repeated>”，表示“!”被多次重复以表达语气加强，同时假设重复次数不影响反讽的类型。

\item 将字母被故意重复的单词以“<elongated>”示意，如“Noooooooo”替换成序列“No”和“<elongated>”，表示“No”中某一个或多个字母被多次重复，但假设被重复的字符和重复的次数与反讽类型无关。

\item 将数字串替换成“<num>”，将电话号码替换成“<phone>”，将日期和时间分别替换成“<date>”和“<time>”，将数字百分比替换成“<percentage>”，超链接替换成“<url>”

\item 将由多个标点符号组成的表情符替换成对应的情感标签，如将“:)”替换成“<happy>”，将“:((”替换成“<sad>”。

\item 在完成以上处理后，对英文的大小写统一转换成小写。

\end{itemize}

以上功能我们利用了第三方的英语微博文本处理工具\textit{ekphrasis}\footnote{https://github.com/cbaziotis/ekphrasis}完成，对于其中如何分词、如何识别电话号码和日期、以及颜文字到情感标签的详细映射关系列表，读者可以直接参考其代码实现和配置文件。

\subsection{实验设置}

以下实验主要分成两大部分。第一部分是分析不同模型在不同子分类问题下的性能，根据章节\ref{sec:exp_irony_det_framework}，我们最终的反讽识别框架涉及以下多个子分类问题：区分四个反讽类别的四分类问题、区分“没有反讽”和“基于相反语义的反讽”的二分类问题、区分“没有反讽”和“情景反讽”的二分类问题、区分“没有反讽”和“其他反讽”的二分类问题。对于各个子分类问题，我们基于章节~\ref{sec:exp_irony_det_framework}中的子分类模型框架进行实验，透过采用不同配置了解不同模型文本反讽识别的拟合能力。

第二部分是分析我们设计的识别系统的性能。我们会观察每一轮决策的调整如何改变局部的预测结果，而这些局部变化如何影响系统的整体性能。

%另外我们也会透过对设计的系统框架进行修改和比较，分析设计的合理性，以及当尝试将这种识别系统设计方式应用到其他场景时有哪些细节值得注意。

\subsection{评价指标}

按照国际比赛SemEval-2018任务三的设置，各个任务均以F1值作为识别系统性能的主要评价指标。对于其中一个类别$c$的F1值，其定义如下：

\begin{align}
  F_c = \frac{2 \times P_c \times R_c}{P_c + R_c} 
\end{align}

其中 $P_c$ 为类别$c$的正确率，$R_c$ 为类别$c$的召回率，其定义如下：

\begin{align}
  P_c &= \frac{TP_c}{TP_c + FP_c} \\
  R_c &= \frac{TP_c}{TP_c + FN_c}
\end{align} 

其中$TP_c$表示被系统预测为类别$c$，且真实标签为类别$c$的样本数量；$FP_c$表示被系统预测为类别$c$，但真实标签不是类别$c$的样本数量；$FN_c$被系统预测为不是类别$c$，但真实标签为类别$c$的样本数量。对于子任务一，系统性能以“带有反讽”一类样本的F1值为主要评估指标。对于子任务二，系统性能以各个类别的F1值的宏平均作为主要评价指标，即：

\begin{align}
  F1-macro = \sum\limits_{c \in C}F_c
\end{align}

此处$C$对应子任务二中四个类别组成的集合，即\{没有反讽，基于相反语义的反讽，情景反讽，其他反讽\}。在以下实验中，我们除了观察F1值、正确率和召回率，我们还会给出模型的准确率，其定义如下：

\begin{align}
  Acc &= \frac{\sum\limits_{c \in C} TP_c}{\sum\limits_{c \in C}(TP_c + FP_c)}
\end{align}

其中$TP_c$和$FP_c$如前述的定义，而$C$在子任务一中对应两个类别组成的集合，即\{没有反讽，带有反讽\}。

\subsection{模型训练}
\label{ssec:exp_irony_det_model_training}

对于不同的模型，我们都采用了以下策略来进行训练：

\begin{itemize}

\item 对于每个子分类器，在训练开始前我们先从每一类的训练样本中随机选出10\%的样本作为验证集，以此保留各个类的样本量分布。在每一轮模型训练中，学习算法基于另外90\%的训练样本对网络参数进行调整，然后计算模型在验证集上的F1值，经过有限轮迭代后，取在验证集上达到最优F1值的网络参数作为该子分类器最终的参数，以此缓解在训练数据上过拟合的问题。另外由于最终预测结合由多个子分类器投票联合得出，为了充分运用训练数据，每个分类器的验证集为独立随机筛选得出，一方面保证每个训练样本都有概率被用于某个分类器的参数调整，另一方面使得各个分类器的训练数据不同，因此对文本特征的建模也会有所不同，理论上对过拟合同样有缓解的作用，更有利于最后的投票。

\item 对于词嵌入层，我们利用了章节\ref{ssec:embedding}中提到的Baziotis等人\cite{baziotis2018ntua}提供的词嵌入模型，直接用于初始化词嵌入层的参数。在训练过程中，我们不对词嵌入层的参数进行调整。考虑到若允许词嵌入层的参数调整，那么只有在训练集中出现过的词的词向量有机会被修改，词嵌入空间因此有所改动，只出现在验证集或测试集上的词的词向量在新的词嵌入空间中表达的意义就有可能出现偏差。另外对于词嵌入模型中未被覆盖的单词，若它在至少2个训练样本中出现，则为其随机生成词向量。

\item 在训练阶段中，我们在词嵌入层后添加高斯噪音。由于词嵌入算法在原理上使得意思相似的单词投影到词嵌入空间中距离相近的点上，高斯噪音的添加相当于把原本的单词替换成近义词，使得模型能更好地识别近义词构成的语言模式，另一方面缓解过拟合的问题。在验证和测试阶段，高斯躁音的标准方差被调整为零，即不起作用。

\item 在训练阶段中，我们在特征编码器和概率预测器之间添加了Dropout层，以概率$p_{Dropout}$将特征编码器得出特征向量上的各位数值置为零，并对没有被置零的各位数值乘以常量 $\frac{1}{1-p_{dropout}}$。在验证和测试阶段，Dropout层不起作用。

\item 在模型训练的损失函数，我们以权重$l_2$加入了概率预测器中全联接层的权重（不包括偏移量）的L2正则项。

\item 在面向“没有反讽”和“其他反讽”的二分类问题中，由于两个类别的样本数据差异较大（1923：205），当人工神经网络根据样本的误差透过反向传播进行学习时，如果所有样本的权重相同，模型会倾向于把所有样本判断为样本量够多的“没有反讽”。为此我们根据样本量的分布决定各个类别的样本的权重。如公式\ref{eq:class_weight}所示，其中$w_c$表示类别$c$对应每个样本的权重，$N$表示总的训练样本数，$C$表示该子分类问题的类别集合，此处即为\{没有反讽，其他反讽\}，$N_c$示类别$c$对应的训练样本数。

\end{itemize}

\begin{align}
    \label{eq:class_weight}
    w_c = \frac{N}{|C| \times N_c}
\end{align}

\subsection{结果与分析}

\subsubsection{面向“带有反讽”和“没有反讽”的二分类模型性能分析}

对面向“带有反讽”和“没有反讽”的二分类问题，表~\ref{tab:exp_irony_det_A_single_result}和图~\ref{fig:exp_irony_det_A_single_result_bar}显示不同卷积神经网络和迭归神经网络在我们模型框架中能达到的性能。注意表中的正确率、召回率、F1值均是针对类别“带有反讽”的指标，对应比赛SemEval2018任务三子任务一关注的主要指标。

对于F1值，2层BiLSTM的表现最好，其次是LSTM配合注意力机制，其F1值和前者非常靠近（偏差约0.001），第三为单层的BiLSTM，其F1值和前两者则偏差较大（约0.01）。对于准确率，单层BiLSTM配合注意力机制和2层BiLSTM配合注意力机制达到最好的数值0.6888 ，第三为LSTM配合注意力机制，其准确率和前两者偏差较小（约0.026）。对于正确率，2层BiLSTM配合注意力机制达到最好的数值0.5870 ，其次是单层BiLSTM配合注意力机制，与前者偏差较小（约0.001），第三的LSTM配合注意力机制则和和前两者则偏差较大（约0.01）。对于召回率，单层的LSTM达到最好的0.8617 ，第二的2层BiLSTM差距则较大（约0.04）。

对于单层BiLSTM和2层BiLSTM，添加注意力机制都使得准确率和“带有反讽”的正确率有所提升，但同时“带有反讽”的召回率明显下降，导致“带有反讽”的F1值也连带下降，可见BiLSTM和2层BiLSTM添加注意力机制后整个模型的拟合能力是有上升的，但更倾向于预测样本为“没有反讽”，导致“带有反讽”的召回率下降，相对地更少比例的样本被误判为“带有反讽”，因而正确率稍为提高。另外CNN在添加注意力机制后，除召回率以外的三项指标都达到了各个模型中最差的性能，可见虽然在公式上注意力机制可以配合CNN使用，但实际性能并不理想。

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{\linewidth}
  \caption{面向“带有反讽”和“没有反讽”的二分类模型性能}
  \label{tab:exp_irony_det_A_single_result}
    \begin{tabularx}{\linewidth}{X|llll}
    \toprule[1.5pt]
    & 准确率 & 正确率 & 召回率 & F1值 \\
    \hline
    CNN & 0.6658 (6) & 0.5548 (6) & 0.7974 (5) & 0.6544 (5) \\ % A_cnn_ek_1553221371
    CNN+注意力机制 & 0.6008 (12) & 0.4980 (12) & 0.8039 (3) & 0.6150 (12) \\  % A_cnn_ek_1554345958
    \hline
    GRU & 0.6607 (7) & 0.5542 (7) & 0.7395 (9) & 0.6336 (10) \\ % A_gru_ek_1553070254
    GRU+注意力机制 & 0.6569 (10) & 0.5482 (9) & 0.7685 (7) & 0.6399 (9) \\ % A_gru_ek_1553074900
    \hline
    BiGRU & 0.6594 (8) & 0.5534 (8) & 0.7331 (10) & 0.6307 (11) \\ % A_bgru_ek_1553075855
    BiGRU+注意力机制 & 0.6582 (9) & 0.5473 (10) & 0.8006 (4) & 0.6501 (7) \\ % A_bgru_ek_1553068355
    \hline
    LSTM & 0.6390 (11) & 0.5276 (11) & \bf 0.8617 (1) & 0.6545 (4) \\ % A_lstm_ek_1553071939
    LSTM+注意力机制 & 0.6862 (3) & 0.5768 (3) & 0.7846 (6) & 0.6640 (2) \\ % A_lstm_ek_1553075765
    \hline
    BiLSTM & 0.6798 (4) & 0.5721 (4) & 0.7653 (8) & 0.6547 (3) \\ % A_blstm_ek_1553075473
    BiLSTM+注意力机制 & \bf 0.6888 (1) & 0.5861 (2) & 0.7331 (10) & 0.6514 (6) \\ % A_blstm_ek_1553583756
    \hline
    2层BiLSTM & 0.6709 (5) & 0.5577 (5) & 0.8232 (2) & \bf 0.6649 (1) \\ % A_nblstm_ek_1554346535
    2层BiLSTM+注意力机制 & \bf 0.6888 (1) & \bf 0.5870 (1) & 0.7267 (12) & 0.6494 (8) \\ % A_nblstm_ek_1554346515
    \bottomrule[1.5pt]
    \end{tabularx}
  \end{minipage}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{img/exp_irony_det_A_single_result_bar.png}
  \caption{面向“带有反讽”和“没有反讽”的二分类模型性能}
  \label{fig:exp_irony_det_A_single_result_bar}
\end{figure}

\subsubsection{面向反讽四分类的模型性能分析}

对于面向反讽四分类问题，表~\ref{tab:exp_irony_det_B_result}和图~\ref{fig:exp_irony_det_B_single_result_bar}显示不同卷积神经网络和迭归神经网络在我们模型框架中能达到的性能。注意表中的正确率、召回率、F1值均是
各类别对应指标数据的宏平均，对应比赛SemEval2018任务三子任务二关注的主要指标。

对于F1值，BiGRU达到最好的数值（0.4768），其次是2层BiLSTM以及配合注意力机制的2层BiLSTM，与前者的数值偏差较大（约为0.01）。对于准确率，同样由BiGRU达到最好的数值（0.6722），其次是BiLSTM和2层BiLSTM，和前者的数值偏差也较大（约0.014）。对于正确率，CNN和2层BiLSTM的性能较好（在0.5以上），第三的BiLSTM则在0.49以下。对于召回率，2层BiLSTM配合注意力机制达到最好的0.4864 ，其次的BiGRU和BiLSTM则和前者偏差较大（约0.01）。

另外，六组模型在添加注意力机制后正确率、召回率和F1值都有所下降（仅2层BiLSTM的召回率例外），而对于准确率较高的BiGRU、BiLSTM和CNN在添加注意力机制后准确率同样有所下降，可以认为添加注意力机制在此子分类问题中并不没有带来性能提升。

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{\linewidth}
  \caption{面向反讽四分类的模型性能}
  \label{tab:exp_irony_det_B_result}
    \begin{tabularx}{\linewidth}{X|llll}
    \toprule[1.5pt]
    & 准确率 & 正确率 & 召回率 & F1值 \\
    \hline
    CNN & 0.6531 (4) & \bf 0.5090 (1) & 0.4667 (5) & 0.4432 (7) \\ % B_cnn_ek_1554446864
    CNN+注意力机制 & 0.6186 (10) & 0.4467 (7) & 0.4214 (12) & 0.4030 (12) \\ % B_cnn_ek_1554446879
    \hline
    GRU & 0.6148 (12) & 0.4437 (8) & 0.4693 (4) & 0.4476 (5) \\ % B_gru_ek_1554447274
    GRU+注意力机制 & 0.6531 (4) & 0.4253 (10) & 0.4605 (7) & 0.4370 (8) \\ % B_gru_ek_1554447525
    \hline
    BiGRU & \bf 0.6722 (1) & 0.4868 (4) & 0.4779 (2) & \bf 0.4768 (1) \\ % B_bgru_ek_1554447516
    BiGRU+注意力机制 & 0.6301 (9) & 0.4543 (6) & 0.4638 (6) & 0.4497 (4) \\ % B_bgru_ek_1554447697
    \hline
    LSTM & 0.6186 (10) & 0.4313 (9) & 0.4490 (9) & 0.4307 (9) \\ % B_lstm_ek_1554447721
    LSTM+注意力机制 & 0.6416 (6) & 0.4046 (12) & 0.4394 (10) & 0.4148 (11) \\ % B_lstm_ek_1554447878
    \hline
    BiLSTM & 0.6582 (2) & 0.4875 (3) & 0.4537 (8) & 0.4447 (6) \\ % B_blstm_ek_1554447955
    BiLSTM+注意力机制 & 0.6352 (7) & 0.4168 (11) & 0.4386 (11) & 0.4160 (10) \\ % B_blstm_ek_1554448216
    \hline
    2层BiLSTM & 0.6582 (2) & 0.5068 (2) & 0.4762 (3) & 0.4644 (3) \\ % B_nblstm_ek_1554448237
    2层BiLSTM+注意力机制 & 0.6314 (8) & 0.4824 (5) & \bf 0.4864 (1) & 0.4657 (2) \\ % B_nblstm_ek_1554448594
    \bottomrule[1.5pt]
    \end{tabularx}
  \end{minipage}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{img/exp_irony_det_B_single_result_bar.png}
  \caption{面向反讽四分类的模型性能}
  \label{fig:exp_irony_det_B_single_result_bar}
\end{figure}

\subsubsection{面向“没有反讽”和“基于相反语义的反讽”二分类的实验结果分析}

对于面向“没有反讽”和“基于相反语义的反讽”的二分类问题，表~\ref{tab:exp_irony_det_Bb01_result}和图~\ref{fig:exp_irony_det_Bb01_single_result_bar}显示不同卷积神经网络和迭归神经网络在我们模型框架中能达到的性能。注意表中的正确率、召回率、F1值指两个类别对应指标数据的宏平均。

对于F1值，LSTM配合注意力机制达到最大数值的0.7752 ，其后依次为BiGRU和GRU，和前者差距约较小（0.005)。对于准确率，同样是LSTM配合注意力机制达到最好的效果（0.8275），其后依次为GRU和BiGRU，和前者差距大（0.015）。对于正确率，还是 LSTM配合注意力机制的数值最高（0.7717），其后依次为GRU和BiGRU，和前者差距大（0.015）。对于召回率，数值最高的是BiGRU（0.7993），其次是GRU和LSTM，和前者差距均较小（约0.005）。

总的来说，LSTM配合注意力机制在四项指标中的三项都达到了最好的性能，而各项指标的第二和第三基本上由GRU和BiGRU达到。由配合注意力机制的模型达到最好的性能，这一点和前面各个子分类问题的实验结果都不同，显示注意力机制可能对“基于相反语义的反讽”有相应的建模能力。另外GRU和BiGRU的性能非接近，从数学模型上看，BiGRU比单层GRU多一个把文本反向输入的GRU通道，提高了召回率的同时稍微降低了准确率和正确率，显示反向输入的GRU通道能额外捕足到“基于相反语义的反讽”相关的特征。但相对地BiLSTM在四项指标上都明显低于LSTM，我们认为其中的原因可能有两点，一是LSTM从数学模型上对“基于相反语义的反讽”的特征建模能力较差，二是BiLSTM的模型参数过多而导致对训练集的过拟合。


\begin{table}[htb]
  \centering
  \begin{minipage}[t]{\linewidth}
  \caption{面向“没有反讽”和“基于相反语义的反讽”的二分类各模型性能}
  \label{tab:exp_irony_det_Bb01_result}
    \begin{tabularx}{\linewidth}{X|llll}
    \toprule[1.5pt]
    & 准确率 & 正确率 & 召回率 & F1值 \\
    \hline
    CNN & 0.7991 (5) & 0.7438 (5) & 0.7791 (7) & 0.7562 (5) \\ % Bb01_cnn_ek_1554448736
    CNN+注意力机制 & 0.6829 (12) & 0.6494 (12) & 0.6909 (12) & 0.6470 (12) \\ % Bb01_cnn_ek_1554448788
    \hline
    GRU & 0.8100 (2) & 0.7566 (2) & 0.7944 (2) & 0.7699 (3) \\ % Bb01_gru_ek_1554448924
    GRU+注意力机制 & 0.7677 (9) & 0.7196 (9) & 0.7679 (10) & 0.7303 (9) \\ % Bb01_gru_ek_1554449053
    \hline
    BiGRU & 0.8085 (3) & 0.7565 (3) & \bf 0.7993 (1) & 0.7705 (2) \\ % Bb01_bgru_ek_1554449115
    BiGRU+注意力机制 & 0.7755 (8) & 0.7301 (8) & 0.7831 (5) & 0.7412 (8) \\ % Bb01_bgru_ek_1555407125
    \hline
    LSTM & 0.8053 (4) & 0.7525 (4) & 0.7932 (3) & 0.7661 (4) \\ % Bb01_lstm_ek_1554449707
    LSTM+注意力机制 & \bf 0.8257 (1) & \bf 0.7717 (1) & 0.7791 (7) & \bf 0.7752 (1) \\ % Bb01_lstm_ek_1554449864
    \hline
    BiLSTM & 0.7551 (10) & 0.7169 (10) & 0.7734 (9) & 0.7236 (10) \\ % Bb01_blstm_ek_1554449881
    BiLSTM+注意力机制 & 0.7174 (11) & 0.6909 (11) & 0.7460 (11) & 0.6889 (11) \\ % Bb01_blstm_ek_1554450198
    \hline
    2层BiLSTM & 0.7849 (7) & 0.7339 (7) & 0.7795 (6) & 0.7465 (7) \\ % Bb01_nblstm_ek_1554450231
    2层BiLSTM+注意力机制 & 0.7928 (6) & 0.7421 (6) & 0.7888 (4) & 0.7554 (6) \\ % Bb01_nblstm_ek_1554450448
    \bottomrule[1.5pt]
    \end{tabularx}
  \end{minipage}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{img/exp_irony_det_Bb01_single_result_bar.png}
  \caption{面向“没有反讽”和“基于相反语义的反讽”的二分类各模型性能}
  \label{fig:exp_irony_det_Bb01_single_result_bar}
\end{figure}

\subsubsection{面向“没有反讽”和“情景反讽”二分类的模型性能分析}

对于面向“没有反讽”和“情景反讽”的二分类问题，表~\ref{tab:exp_irony_det_Bb02_result}和图~\ref{fig:exp_irony_det_Bb02_single_result_bar}显示不同卷积神经网络和迭归神经网络在我们模型框架中能达到的性能。注意表中的正确率、召回率、F1值指两个类别对应指标数据的宏平均。

对于F1值和召回率，2层BiLSTM配合注意力机制在这两个指标上都达到了最好的效果（数值分别为0.6924 和 0.6806），其次是2层BiLSTM，第三是单层的BiLSTM配合注意力机制，但后两者在准确率和正确率这两项指标上都排在靠后的位置。而对于准确率和正确率，均由CNN达到最好的效果（数值分别为0.8656和 0.7634），其次是2层BiLSTM配合注意力机制，第三是单层的LSTM。

整体上，2层BiLSTM配合注意力机制在四项指标上的都达到了靠前的效果，显示2层BiLSTM配合注意力机制对“情景反讽”有明显较好的建模能力。另外CNN虽然在准确率和正确率上都达到最好的性能，但由于召回率数值太低导致了F1值明显低于第一的F1值（差距约0.045），显示CNN只对部分“情景反讽”的样本有较好的识别能力，导致了召回率偏低。

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{\linewidth}
  \caption{面向“没有反讽”和“情景反讽”的二分类模型性能}
  \label{tab:exp_irony_det_Bb02_result}
    \begin{tabularx}{\linewidth}{X|llll}
    \toprule[1.5pt]
    & 准确率 & 正确率 & 召回率 & F1值 \\
    \hline
    CNN & \bf 0.8656 (1) & \bf 0.7634 (1) & 0.6167 (7) & 0.6473 (7) \\ % Bb02_cnn_ek_1554450719
    CNN+注意力机制 & 0.8477 (5) & 0.6865 (5) & 0.5917 (11) & 0.6117 (11) \\ % Bb02_cnn_ek_1554450772
    \hline
    GRU & 0.8495 (4) & 0.6942 (4) & 0.6024 (10) & 0.6242 (10) \\ % Bb02_gru_ek_1554450862
    GRU+注意力机制 & 0.8333 (11) & 0.6708 (8) & 0.6556 (4) & 0.6625 (4) \\ % Bb02_gru_ek_1554451013
    \hline
    BiGRU & 0.8423 (6) & 0.6645 (11) & 0.5789 (12) & 0.5951 (12) \\ % Bb02_bgru_ek_1554451047
    BiGRU+注意力机制 & 0.8423 (6) & 0.6825 (6) & 0.6416 (5) & 0.6572 (6) \\ % Bb02_bgru_ek_1554451155
    \hline
    LSTM & 0.8513 (2) & 0.7027 (3) & 0.6372 (6) & 0.6590 (5) \\ % Bb02_lstm_ek_1554451286
    LSTM+注意力机制 & 0.8387 (8) & 0.6676 (10) & 0.6153 (8) & 0.6325 (8) \\ % Bb02_lstm_ek_1554451194
    \hline
    BiLSTM & 0.8351 (10) & 0.6575 (12) & 0.6084 (9) & 0.6243 (9) \\ % Bb02_blstm_ek_1554451336
    BiLSTM+注意力机制 & 0.8369 (9) & 0.6797 (7) & 0.6674 (3) & 0.6731 (3) \\ % Bb02_blstm_ek_1554451401
    \hline
    2层BiLSTM & 0.8262 (12) & 0.6691 (9) & 0.6803 (2) & 0.6743 (2) \\ % Bb02_nblstm_ek_1554451496
    2层BiLSTM+注意力机制 & 0.8513 (2) & 0.7076 (2) & \bf 0.6806 (1) & \bf 0.6924 (1) \\ % Bb02_nblstm_ek_1554451575
    \bottomrule[1.5pt]
    \end{tabularx}
  \end{minipage}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{img/exp_irony_det_Bb02_single_result_bar.png}
  \caption{面向“没有反讽”和“情景反讽”的二分类模型性能}
  \label{fig:exp_irony_det_Bb02_single_result_bar}
\end{figure}

\subsubsection{面向“没有反讽”和“其他反讽”二分类的模型性能分析}

对于面向“没有反讽”和“其他反讽”的二分类问题，表~\ref{tab:exp_irony_det_Bb03_result}和图~\ref{fig:exp_irony_det_Bb03_single_result_bar}显示不同卷积神经网络和迭归神经网络在我们模型框架中能达到的性能。注意表中的正确率、召回率、F1值指两个类别对应指标数据的宏平均。

对于F1值，性能最好的是CNN（0.6016），其次是GRU，与前者差距较大（约0.016），第三为BiLSTM，明显低于CNN的数值（差距约为0.05）。对于准确率，同样是CNN达到最高的数值（0.8860），其次是GRU配合注意力机制以及LSTM配合注意力机制，在数值上比较接近（差距仅0.002）。对于正确率，依然是CNN的性能最优（0.7123），第二是GRU配合注意力机制，但和前者差距较明显（约0.02），第三的GRU则远差于前两者（差距达0.1以上)。 对于召回率，则是GRU的效果最好（0.5836），其次是CNN，与前者差距较小（约0.005），第三的BiLSTM则和前两者差距较大（达0.03以上）。

整体上，CNN在三项指标上的都达到了最好的效果，而在召回率也逼近最好的GRU，显示CNN对“其他反讽”有明显较好的建模能力。对于CNN在准确率和正确率上最佳，这和面向“没有反讽”和“情景反讽”的二分类实验结果相同，这可能有样本量分布有关，“情景反讽”和“其他反讽”的训练样本量（分别为316和205）都远少于“没有反讽”（1923），但CNN对“其他反讽”有较好的建模能力，因此在达到较好召回率的同时达到了最佳的F1值。

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{\linewidth}
  \caption{面向“没有反讽”和“其他反讽”的二分类模型性能}
  \label{tab:exp_irony_det_Bb03_result}
    \begin{tabularx}{\linewidth}{X|llll}
    \toprule[1.5pt]
    & 准确率 & 正确率 & 召回率 & F1值 \\
    \hline
    CNN & \bf 0.8860 (1) & \bf 0.7123 (1) & 0.5781 (2) & \bf 0.6016 (1) \\ % Bb03_cnn_ek_1553500286
    CNN+注意力机制 & 0.7981 (11) & 0.4930 (8) & 0.4934 (11) & 0.4932 (7) \\ % Bb03_cnn_ek_1554453416
    \hline
    GRU & 0.8336 (10) & 0.5873 (3) & \bf 0.5836 (1) & 0.5853 (2) \\ % Bb03_gru_ek_1554452318
    GRU+注意力机制 & 0.8841 (2) & 0.6928 (2) & 0.5070 (7) & 0.4848 (8) \\ % Bb03_gru_ek_1554452300
    \hline
    BiGRU & 0.8411 (8) & 0.5481 (7) & 0.5317 (6) & 0.5353 (6) \\ % Bb03_bgru_ek_1554452373
    BiGRU+注意力机制 & 0.8822 (4) & 0.4419 (11) & 0.4989 (9) & 0.4687 (10) \\ % Bb03_bgru_ek_1554452659
    \hline
    LSTM & 0.8486 (6) & 0.5603 (5) & 0.5360 (4) & 0.5409 (4) \\ % Bb03_lstm_ek_1554452412
    LSTM+注意力机制 & 0.8841 (2) & 0.4421 (10) & 0.5000 (8) & 0.4692 (9) \\ % Bb03_lstm_ek_1554452800
    \hline
    BiLSTM & 0.8430 (7) & 0.5663 (4) & 0.5468 (3) & 0.5527 (3) \\ % Bb03_blstm_ek_1554452497
    BiLSTM+注意力机制 & 0.8822 (4) & 0.4419 (11) & 0.4989 (9) & 0.4687 (10) \\ % Bb03_blstm_ek_1554452804
    \hline
    2层BiLSTM & 0.8355 (9) & 0.5483 (6) & 0.5356 (5) & 0.5393 (5) \\ % Bb03_nblstm_ek_1554452506
    2层BiLSTM+注意力机制 & 0.7944 (12) & 0.4571 (9) & 0.4633 (12) & 0.4600 (12) \\ % Bb03_nblstm_ek_1554452977
    \bottomrule[1.5pt]
    \end{tabularx}
  \end{minipage}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{img/exp_irony_det_Bb03_single_result_bar.png}
  \caption{面向“没有反讽”和“其他反讽”的二分类模型性能}
  \label{fig:exp_irony_det_Bb03_single_result_bar}
\end{figure}

\subsubsection{面向“没有反讽”和“其他反讽”二分类的模型性能分析}


\begin{table}[htb]
  \centering
  \begin{minipage}[t]{\linewidth}
  \caption{SemEval-2018任务三子任务一参赛系统性能}
  \label{tab:exp_irony_det_A_other_comp}
    \begin{tabularx}{\linewidth}{c|X|llll}
    \toprule[1.5pt]
    排名 & 队伍名称 & 准确率 & 正确率 & 召回率 & F1值 \\
    \hline 
    1 & THU\_NGN & \bf 0.7347 (1) & 0.6304 (4) & 0.8006 (4) & \bf 0.7054 \\
    2 & NTUA-SLP & 0.7321 (2) & 0.6535 (2) & 0.6913 (13) & 0.6719 \\
    3 & WLV & 0.6429 (15) & 0.5317 (20) & 0.8360 (2) & 0.6500 \\
    4 & (无) & 0.6607 (10) & 0.5506 (13) & 0.7878 (7) & 0.6481 \\
    5 & NIHRIO, NCL & 0.7015 (3) & 0.6091 (5) & 0.6913 (13) & 0.6476 \\
    6 & DLUTNLP-1 & 0.6276 (19) & 0.5199 (23) & 0.7974 (5) & 0.6294 \\
    7 & ELiRF-UPV & 0.6110 (23) & 0.5059 (27) & 0.8328 (3) & 0.6294 \\
    8 & \bf THU\_HCSI & 0.6594 (11) & 0.5550 (11) & 0.7138 (10) & 0.6245 \\
    9 & CJ & 0.6671 (8) & 0.5654 (9) & 0.6945 (12) & 0.6234 \\ 
    10 & \#NonDicevoSulSerio & 0.6786 (7) & 0.5831 (8) & 0.6656 (15) & 0.6216 \\
    \hline
    15 & (无) & 0.5651 (31) & 0.4731 (33) & \bf 0.8489 (1) & 0.6076 \\
    \hline
    43 & INGEOTEC-IIMAS & 0.6276 (19) & \bf 0.8800 (1) & 0.0707 (37) & 0.1310 \\
    \hline 
    & 我们的系统 & 0.7258 (3) & 0.6176 (5) & 0.8103 (4) & 0.7010 (2) \\
    \bottomrule[1.5pt]
    \end{tabularx}
  \end{minipage}
\end{table}


\begin{table}[htb]
  \centering
  \begin{minipage}[t]{0.8\linewidth}
  \caption{四分类反讽识别系统最终识别结果和中间结果的性能}
  \label{tab:exp_irony_det_B_ensemble_result}
    \begin{tabularx}{\linewidth}{X|cccc}
    \toprule[1.5pt]
    & 准确率 & 正确率 & 召回率 & F1值 \\
    \hline
    中间结果I & \bf 0.6837 & \bf 0.5512 & 0.5016 & 0.5253 \\
    中间结果II & 0.6811 & 0.5464 & 0.5113 & 0.5282 \\
    中间结果III & 0.6786 & 0.5361 & 0.5498 & 0.5429 \\
    \hline
    最终结果 & 0.6824 & 0.5443 & \bf 0.5531 & \bf 0.5486 \\
    \bottomrule[1.5pt]
    \end{tabularx}
  \end{minipage}
\end{table}

\begin{table}[htb]
  \centering
  \begin{minipage}[t]{\linewidth}
  \caption{SemEval-2018任务三子任务二参赛系统性能} % 共43个参赛系统
  \label{tab:exp_irony_det_B_other_comp}
    \begin{tabularx}{\linewidth}{c|X|llll}
    \toprule[1.5pt]
    排名 & 队伍名称 & 准确率 & 正确率 & 召回率 & F1值 \\
    \hline 
    1 & (无) & \bf 0.7321 (1) & \bf 0.5768 (1) & 0.5044 (4) & \bf 0.5074 \\
    2 & NTUA-SLP & 0.6518 (4) & 0.4959 (4) & 0.5124 (2) & 0.4959 \\
    3 & \bf THU\_NGN & 0.6046 (9) & 0.4860 (6) & \bf 0.5414 (1) & 0.4947 \\
    4 & (无) & 0.6033 (10) & 0.4660 (7) & 0.5058 (3) & 0.4743 \\
    5 & NIHRIO, NCL & 0.6594 (3) & 0.5446 (2) & 0.4475 (5) & 0.4437 \\
    6 & Random Decision Syntax Trees & 0.6327 (6) & 0.4868 (5) & 0.4388 (8) & 0.4352 \\
    7 & ELiRF-UPV & 0.6327 (6) & 0.4123 (12) & 0.4404 (7) & 0.4211 \\
    8 & WLV & 0.6709 (2) & 0.4311 (10) & 0.4149 (9) & 0.4153 \\
    9 & \#NonDicevoSulSerio & 0.5446 (18) & 0.4087 (15) & 0.4410 (6) & 0.4131 \\
    10 & INGEOTEC-IIMAS & 0.6441 (5) & 0.5017 (3) & 0.3850 (15) & 0.4055 \\
    \hline
    & 我们的系统 & 0.6824 (2) & 0.5443 (3) & \bf 0.5531 (1) & \bf 0.5486 (1) \\
    \bottomrule[1.5pt]
    \end{tabularx}
  \end{minipage}
\end{table}

% \subsection{错误分析}

\section{本章小结}

pass

