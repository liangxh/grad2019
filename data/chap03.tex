\chapter{意图识别技术}
\label{cha:tech}

\section{本章引论}

根据前一章中描述的研究框架，在本章中我们将针对每一个功能介绍对应的技术实现，其中包括文本预处理、词特征提取、分类算法、集成学习。对后续实验用中使用到的技术给出相对充分的说明，同时也会相关的技术给出概要的描述，以便于其他研究者在本论文未深入探索的方向作出拓展性的研究。

\section{文本预处理}

文本的预处理是所有面向文本的研究的第一步，其目的是为特征提取做好准备。良好的预处理策略可以在尽可能不掉失重要信息的情况下对样本数据进行简化，增加样本之间重复的模式，减轻模型对数据进行拟合的负担，同时更有效地找出数据之间的相互关系。错误的预处理策略会会掉失具有区分能力的信息，甚至产生具有误导性的样本。由于不同的语言，由于其天然的性质不同，预处理的方法也会各异，以下会重点介绍针对英文的文本预处理技术。

\subsection{分词}

为了从文本提取词级别的特征，我们需要首先将句子切成多个词的序列。

虽然对于英语及大部分欧洲语言，空格隔开的字符必然属于不同的词组，但对应不以空格分隔词组的语言（如中文），分词的作用尤其重要。在某些情况下，分词的结果会影响对句子的理解，如将“乒乓球拍卖完了”切割成“乒乓球拍-卖-完-了”或“乒乓球-拍卖-完-了”，对主体应该是“乒乓球拍”还是“乒乓球”，动词应该是“卖”还是“拍卖”，仅凭字面意思无法确定发言者想表达的意思。特别地社交媒体平台上，新词不断的出现，要正确进行分词就有其独特的难点。而分词并不只针对语言中的单词，还针对标点符号或其他特征字符组成的有特殊语义或情感的字符组合，如现今社交媒体上普遍用多个字符拼接成颜文字，其中最常见的微笑的表情“:)”和伤心的表情“:(”，但如果在分词过程中把前者分割成“:”和“)”就会失去其所带的正向情感信息，这在短文本的情感识别中非常关键。

虽然利用空格和标点符号在大部分情况下可以完成对英语句子的分词，但在一些情况下，标点符号作用为词组的一部分而不是词组的分隔符，而在社交媒体上会有空格被省略的情况，以下是一些需要额外处理的情况\cite{jackson2007natural}\cite{mitkov2004oxford}。一是带句号的缩写，如“U.S.”，“.com”，句号应该作为词的一部分，或按句号切割“U.S.”将失去其语义。二是具有一定格式的带标点符号的词组，如电子邮箱地址（如example@email.com）、时间（如 Jan 6th、06/01/19）、电话号码（如(123)456-7890）、网页地址（如www.example.com）等，而在大部分情况下，我们会优先关注这个字符串指的是什么类型的事物而不是细节，譬如将一个句子中的电子邮箱地址或电话号码作替换并不会改变其情感的表达，但识别出一个字符串对应的事情类型，并在清楚它对意图识别没有关联的情况下对其忽略是有意义的。第三种情况是附属词，如“'t”对应“not”，只有正确识别“'”的作用才能识别出否定的意思，否则句子的意思将完全相反。值得注意的是，对社交媒体平台上的文本，除了以上在正规英语中会出现的情况，还有出现其他特殊情况，如“Y!E!S!”和“N!O!”。这需要对数据首先进行人工观察找出特殊的模式，再对语料库进行统计判断其出现频率，若出现频率较高则新增处理规则将对应模式做转换（如将“Y!E!S!”替换成“YES!!!”）或对问题无关的模式忽略（如国外的微博以“RE：”开头表示回复，并不包含任何情感）。

\subsection{}

\subsection{}


\section{特征提取}

pass

\subsection{词嵌入}

pass

\subsection{词汇特征} % Lexical Feature 

% 多元语法 n-gram
%   统计数据集中多元语法的词频(TF)和逆文本频率(IDF)
%   取TF-IDF最高的N个多元语法
%   对每个条微博得出一个N维向量, 每一维分别对应一个多元语法，其值为该多元语法在该条微博中的数量乘以该多元语法在整个数据集中的IDF
%   每条微博的向量分别进行归一化
% 单词数量
% 字母数量

\subsection{句法特征} % Syntactic features 

% 对文本中单词转换成词性(Part-of-speech, POS)标注
% 和词汇特征中多元语法一样的计算的TF-IDF特征

\subsection{语义特征} % Semantic features

% 词向量平均和
%   对文本进行分词
%   将单词序列转换成词向量序列
%   取词向量序列的平均和作为特征
% 潜在语义
%   利用潜在语义分析(Latent semantic analysis, LSA)从训练集学习单词间的隐藏概念
%   再分别对测试集各个样本提取隐藏概念
% 词类分布
%   利用布朗聚类(Brown Clustering)对训练集的单词进行聚类(N类)
%   每段文本得出一个N维向量，各维对应该文本中包含该类单词的数量

\subsection{基于人工神经网络}

% 人工神经网络对每一个输入进行预测的中间结果可被认为是该输入的隐藏特征
% 利用不同标注的数据集训练的人工神经网络可以用作对应类型的特征提取，如
%  SemEval2014 Task 9: 标注为文本的正负中性情感
%  SemEval2018 Task 1: 标注为文本中是否分别包含了11种情感


\section{分类算法}

pass

\subsection{传统机器学习方法}

% 支持向量机 Support Vector Machine, SVM
% 决策树 Decision Tree
% 随机森林 Random Forest

\subsection{深度学习方法}

% Gated Recurrent Unit, GRU 
% 长短期记忆网络 Long Short-Term Memory, LSTM
% 双向长短期记忆网络 Bidirectional Long Short-Term Memory, BLSTM
% 卷积神经网络 Convolutional Neural Network CNN

\section{集成学习}

pass

% 后融合
%   结合多个子系统的预测结果，根据特定策略得出新的预测结果

%   多数投票 Majority Voting / Hard Voting
%     每个模型分别给出预测标签
%     取最多模型预测的标签作为最终预测结果

%   加权多数投票 Weighted Majority Vote
%     每个模型分别给出预测标签
%     对这些模型的预测标签进行加权投票，取投票最多的标签作为预测结果

%   加权平均概率投票 Soft Voting
%     每个模型分别给出各个标签的预测概率
%     对每个模型的预测概率进行加权不均，取概率最高的标签作为预测结果


\section{本章小结}

pass
